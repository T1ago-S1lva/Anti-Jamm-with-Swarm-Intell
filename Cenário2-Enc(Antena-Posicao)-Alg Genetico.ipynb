{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import Env, spaces\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from plotly.offline import iplot\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.legend_handler import HandlerPatch,HandlerTuple\n",
    "import matplotlib.patches as patches\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import Env, spaces\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.patches import FancyArrowPatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurar o Enxame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_drones = 4\n",
    "limite_y = 80\n",
    "limite_x = 100\n",
    "alcance_comunicacao_jammer = 25\n",
    "alcance_comunicacao_nos = 5000\n",
    "B_Hz = 2.4e9\n",
    "posicoes = np.array([[18, 52], [33, 20], [44, 15], [48, 25]])\n",
    "posicao_jammer = np.array([40, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a subgrade dentro da área maior\n",
    "area_size = (100, 100)\n",
    "subgrade_start = (25, 20)  # Ponto inicial da subgrade (x, y)\n",
    "subgrade_size = (50, 40)   # Tamanho da subgrade (largura, altura)\n",
    "resolution = 5             # Resolução da subgrade (distância entre pontos)\n",
    "\n",
    "# Gerar os pontos discretizados na subgrade\n",
    "x_points = np.arange(subgrade_start[0], subgrade_start[0] + subgrade_size[0] + 1, resolution)\n",
    "y_points = np.arange(subgrade_start[1], subgrade_start[1] + subgrade_size[1] + 1, resolution)\n",
    "grid_points = np.array(np.meshgrid(x_points, y_points)).T.reshape(-1, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIZUALIZAÇÃO DAS DIREÇÕES DAS ANTENAS ESCOLHIDAS ALEATORIAMENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a distância entre duas posições\n",
    "def distancia(pos1, pos2):\n",
    "    return np.sqrt((pos1[0] - pos2[0])**2 + (pos1[1] - pos2[1])**2)\n",
    "\n",
    "# Função para encontrar vizinhos dentro do alcance de comunicação\n",
    "def encontra_vizinhos(posicoes, alcance_comunicacao_nos):\n",
    "    num_drones = posicoes.shape[0]\n",
    "    vizinhos = {}\n",
    "    for i in range(num_drones):\n",
    "        vizinhos[i] = []\n",
    "        for j in range(num_drones):\n",
    "            if i != j and distancia(posicoes[i], posicoes[j]) <= alcance_comunicacao_nos:\n",
    "                vizinhos[i].append(j)\n",
    "    return vizinhos\n",
    "\n",
    "# Função para verificar quais drones são afetados pelo jammer\n",
    "def verifica_jammer(posicoes, posicao_jammer, alcance_comunicacao_jammer):\n",
    "    afetados_pelo_jammer = []\n",
    "    for i in range(posicoes.shape[0]):\n",
    "        if distancia(posicoes[i], posicao_jammer) <= alcance_comunicacao_jammer:\n",
    "            afetados_pelo_jammer.append(i)\n",
    "    return afetados_pelo_jammer\n",
    "\n",
    "# Gera direções aleatórias para as antenas\n",
    "direcoes_antena = np.random.uniform(0, 360, size=num_drones)\n",
    "# direcoes_antena = [278, 102, 235, 312, 182, 242]\n",
    "afetados_pelo_jammer=verifica_jammer(posicoes, posicao_jammer, alcance_comunicacao_jammer)\n",
    "# Comprimento das setas para indicar a direção das antenas\n",
    "comprimento_seta = 5\n",
    "\n",
    "\n",
    "\n",
    "# Visualização usando Matplotlib\n",
    "def render_v2(posicoes, direcoes_antena, posicao_jammer, comprimento_seta=5, area_size=(100, 100)):\n",
    "    afetados_pelo_jammer = verifica_jammer(posicoes, posicao_jammer, alcance_comunicacao_jammer)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 4))\n",
    "\n",
    "    # Desenha os drones no gráfico\n",
    "    for i, pos in enumerate(posicoes):\n",
    "        ax.scatter(pos[0], pos[1], color='blue', s=100, label='Drone' if i == 0 else \"\")\n",
    "        ax.text(pos[0], pos[1] - 2, f'{i}', horizontalalignment='center', color='white', fontweight='bold')\n",
    "\n",
    "    # Desenha as setas para a direção das antenas\n",
    "    for i, direcao in enumerate(direcoes_antena):\n",
    "        direcao_rad = np.radians(direcao)  # Converte para radianos\n",
    "        dx = comprimento_seta * np.cos(direcao_rad)  # Deslocamento em x\n",
    "        dy = comprimento_seta * np.sin(direcao_rad)  # Deslocamento em y\n",
    "        \n",
    "        ax.arrow(\n",
    "            posicoes[i][0], posicoes[i][1], \n",
    "            dx, dy, \n",
    "            head_width=2, head_length=2, fc='b', ec='b'\n",
    "        )  # Seta azul para indicar a direção da antena\n",
    "\n",
    "    # Desenha o jammer\n",
    "    ax.scatter(posicao_jammer[0], posicao_jammer[1], color='red', s=100, marker='o', label='Jammer')\n",
    "\n",
    "    # Configurações finais do gráfico\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_xlim(0, area_size[0])\n",
    "    ax.set_ylim(0, area_size[1])\n",
    "    ax.set_yticks(np.arange(0, area_size[1]+1, 20))\n",
    "    plt.title('Direções das Antenas UAV')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='small')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "render_v2(posicoes, direcoes_antena, posicao_jammer, comprimento_seta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCULO DE TODOS OS ANGULOS A USAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Função para calcular o ângulo entre dois nós em relação à direção da antena\n",
    "def angulo_entre_nos(pos1, direcao_antena, pos2):\n",
    "    # Vetor entre os dois nós\n",
    "    delta_x = pos2[0] - pos1[0]\n",
    "    delta_y = pos2[1] - pos1[1]\n",
    "    \n",
    "    # Direção do vetor em graus\n",
    "    direcao_vetor_rad = np.arctan2(delta_y, delta_x)\n",
    "    direcao_vetor_deg = np.degrees(direcao_vetor_rad)\n",
    "    \n",
    "    # Diferença entre a direção do vetor e a direção da antena\n",
    "    angulo = direcao_vetor_deg - direcao_antena\n",
    "    \n",
    "    # Ajustar para o intervalo de 0 a 360 graus\n",
    "    angulo = angulo % 360  # Usa módulo para garantir que o valor esteja entre 0 e 360\n",
    "    angulo_arredondado = round(angulo)\n",
    "    \n",
    "    return angulo_arredondado\n",
    "\n",
    "# Posições dos drones\n",
    "# posicoes = np.array([[16, 30], [18, 48], [44, 15], [23, 73], [45, 73], [50, 50]])\n",
    "\n",
    "# Direções aleatórias das antenas\n",
    "# direcoes_antena = np.random.uniform(0, 360, size=posicoes.shape[0])\n",
    "\n",
    "# Matriz para armazenar os ângulos\n",
    "angulos_matriz = np.zeros((posicoes.shape[0], posicoes.shape[0]))\n",
    "\n",
    "# Calcular os ângulos para todas as combinações de drones\n",
    "for i in range(posicoes.shape[0]):\n",
    "    for j in range(posicoes.shape[0]):\n",
    "        if i != j:\n",
    "            angulos_matriz[i, j] = angulo_entre_nos(posicoes[i], direcoes_antena[i], posicoes[j])\n",
    "\n",
    "# Apresentar os ângulos entre drones sem valores negativos\n",
    "for i in range(posicoes.shape[0]):\n",
    "    print(f\"Drones que o drone {i} 'vê' com um ângulo:\")\n",
    "    for j in range(posicoes.shape[0]):\n",
    "        if i != j:\n",
    "            angulo_arredondado = int(round(angulos_matriz[i, j]))  # Arredondar para unidade\n",
    "            print(f\"  Com o drone {j}: {angulo_arredondado} graus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETROS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ptx_dBm = 20 \n",
    "f = 2.4e9 \n",
    "B_Hz= 2.4e9\n",
    "d0=1\n",
    "gamma=2\n",
    "sigma = 0\n",
    "c=3e8\n",
    "lambda_m=c/f\n",
    "L0=30\n",
    "potencia_jammer_dBm =100\n",
    "\n",
    "# Ler o arquivo de ganhos para criar uma tabela de busca\n",
    "ganhos_df = pd.read_csv('ganhos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angulos = np.deg2rad(ganhos_df['angulo'])  # Converter graus para radianos\n",
    "ganhos = ganhos_df['ganho']\n",
    "\n",
    "# Criar um gráfico polar\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.plot(angulos, ganhos, linestyle='-', linewidth=1, label='Ganho da Antena')\n",
    "\n",
    "# Ajustar o layout\n",
    "ax.set_theta_zero_location('N')  # Configurar a direção Norte como o topo do gráfico\n",
    "ax.set_theta_direction(-1)  # Configurar a direção dos ângulos para sentido horário\n",
    "ax.set_rmax(max(ganhos) + 1)  # Ajustar o raio máximo para melhor visualização\n",
    "ax.set_rticks(np.linspace(min(ganhos), max(ganhos), num=5))  # Definir os ticks para o raio\n",
    "ax.set_rlabel_position(45)  # Posicionar os labels do raio\n",
    "\n",
    "# Configurar os ticks para o ângulo\n",
    "ax.set_xticks(np.deg2rad(np.arange(0, 360, 30)))  # Definir marcas de ângulo a cada 30 graus\n",
    "\n",
    "# Adicionar legenda e título\n",
    "ax.legend()\n",
    "ax.set_title('Ganho da Antena por Ângulo', va='bottom')\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_ganhos( angulo):\n",
    "    # Arredondar para o ângulo inteiro mais próximo\n",
    "    angulo_ajustado = int(round(angulo))\n",
    "    \n",
    "    if angulo_ajustado==360:\n",
    "        angulo_ajustado=0\n",
    "    \n",
    "    # Encontrar o ganho correspondente ao ângulo ajustado\n",
    "    ganho = ganhos_df.loc[ganhos_df['angulo'] == angulo_ajustado, 'ganho'].iloc[0]\n",
    "    \n",
    "    return ganho\n",
    "\n",
    "\n",
    "\n",
    "# Função para calcular os ganhos de transmissão e recepção\n",
    "def calcula_ganhos(posicoes, direcoes_antena, indice_transmissor, indice_receptor, ganhos_df):\n",
    "    # Verificar se o índice está dentro do limite de direcoes_antena\n",
    "    if indice_transmissor >= len(direcoes_antena) or indice_receptor >= len(direcoes_antena):\n",
    "        print(f\"Erro: índice fora dos limites de direcoes_antena. Transmissor: {indice_transmissor}, Receptor: {indice_receptor}, Tamanho de direcoes_antena: {len(direcoes_antena)}\")\n",
    "        return 0, 0  # Retorne ganhos padrão ou levante um erro\n",
    "\n",
    "    # Obter posições e direções\n",
    "    pos1 = posicoes[indice_transmissor]\n",
    "    pos2 = posicoes[indice_receptor]\n",
    "    direcao_antena1 = direcoes_antena[indice_transmissor]\n",
    "    direcao_antena2 = direcoes_antena[indice_receptor]\n",
    "\n",
    "    # Calcular o ângulo entre os dois nós em relação à direção da antena\n",
    "    angulo_transmissao = angulo_entre_nos(pos1, direcao_antena1, pos2)\n",
    "    angulo_rececao = angulo_entre_nos(pos2, direcao_antena2, pos1)\n",
    "\n",
    "    # Obter os ganhos para transmissão e recepção\n",
    "    ganho_transmissao = busca_ganhos(angulo_transmissao)\n",
    "    ganho_rececao = busca_ganhos(angulo_rececao)\n",
    "    \n",
    "    return ganho_transmissao, ganho_rececao\n",
    "\n",
    "# ganho_transmissao, ganho_rececao = calcula_ganhos(posicoes, direcoes_antena, 0, 1, ganhos_df)\n",
    "\n",
    "\n",
    "\n",
    "def calcula_potencia_recebida(Ptx_dBm, ganho_transmissao, ganho_rececao, d,f):\n",
    "    \"\"\"\n",
    "    Calcula a potência do sinal recebido usando a equação de Friis.\n",
    "    \"\"\"\n",
    "    # L = (4 * np.pi * d / lambda_m)**2\n",
    "    # Prx_dBm = Ptx_dBm + ganho_transmissao + ganho_rececao - 10 * np.log10(L)\n",
    "    # return Prx_dBm\n",
    "    # Calcular a perda de percurso\n",
    "    if d > 0:\n",
    "        L = L0 + 10 * gamma * np.log10(d / d0) + np.random.normal(0, sigma)\n",
    "    else:\n",
    "        L = L0  # Se a distância for zero, assume-se a perda na distância de referência\n",
    "\n",
    "    # Calcular a potência do sinal recebido\n",
    "    Prx_dBm = Ptx_dBm + ganho_transmissao + ganho_rececao - L\n",
    "\n",
    "    return Prx_dBm\n",
    "\n",
    "def calcula_potencia_jammer(pos_drone, direcao_antena_drone, pos_jammer, potencia_jammer_dBm, ganhos_df):\n",
    "    # Calcular a distância entre o drone e o jammer\n",
    "    d = distancia(pos_drone, pos_jammer)\n",
    "    \n",
    "    # Calcular o ângulo entre o drone e o jammer\n",
    "    angulo_entre_drone_e_jammer = angulo_entre_nos(pos_drone, direcao_antena_drone, pos_jammer)\n",
    "    \n",
    "    # Obter o ganho do drone em direção ao jammer\n",
    "    ganho_drone_para_jammer = busca_ganhos( angulo_entre_drone_e_jammer)\n",
    "    \n",
    "    # Calcular a potência do ruído recebido usando a equação de Friis\n",
    "    L = (4 * np.pi * d / lambda_m) ** 2  # Perda de propagação\n",
    "    potencia_jammer_recebida_dBm = potencia_jammer_dBm + ganho_drone_para_jammer - 10 * np.log10(L)\n",
    "    \n",
    "    return potencia_jammer_recebida_dBm\n",
    "\n",
    "def calcula_capacidade(potencia_sinal_dBm, potencia_ruido_dBm):\n",
    "    \"\"\"\n",
    "    Calcula a capacidade do canal em bits por segundo usando a fórmula de Shannon-Hartley.\n",
    "    \"\"\"\n",
    "    # Converter potência em dBm para Watts\n",
    "    potencia_sinal_W = 10 ** (potencia_sinal_dBm / 10) / 1000  # Potência do sinal em Watts\n",
    "    potencia_ruido_W = 10 ** (potencia_ruido_dBm / 10) / 1000  # Potência do ruído em Watts\n",
    "    \n",
    "    # Calcular a razão sinal-ruído (SNR)\n",
    "    snr = potencia_sinal_W / potencia_ruido_W\n",
    "    \n",
    "    # Calcular a capacidade do canal em bits por segundo (bps)\n",
    "    capacidade = B_Hz * np.log2(1 + snr)\n",
    "    \n",
    "    return capacidade/1e3\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "for i in range(posicoes.shape[0]):\n",
    "    for j in range(posicoes.shape[0]):\n",
    "        if i != j:\n",
    "            # Calcular a distância entre os dois drones\n",
    "            d = distancia(posicoes[i], posicoes[j])\n",
    "            \n",
    "            # Calcular os ganhos de transmissão e recepção\n",
    "            ganho_transmissao, ganho_rececao = calcula_ganhos(posicoes, direcoes_antena, i, j, ganhos_df)\n",
    "            # print(posicoes)\n",
    "            print('Ganhos Rx,Tx:',ganho_transmissao, ganho_rececao)\n",
    "            # Calcular a potência do sinal recebido usando a equação de Friis\n",
    "            potencia_recebida = calcula_potencia_recebida(Ptx_dBm, ganho_transmissao, ganho_rececao, d, lambda_m)\n",
    "            potencia_ruido = calcula_potencia_jammer(posicoes[j], direcoes_antena[j], posicao_jammer, potencia_jammer_dBm, ganhos_df)\n",
    "            capacidade_canal=calcula_capacidade(potencia_recebida,potencia_ruido)\n",
    "            # Imprimir a combinação de nós e a potência do sinal recebido\n",
    "            print(f\"  Potencia recebida do drone {i} para o drone {j}: {potencia_recebida:.2f} dBm\")\n",
    "            print(f\"  Ruido recebido no drone {j} e do jammer: {potencia_ruido:.2f} dBm\")\n",
    "            print(f\"  Capacidade do canal {i} para {j}: {capacidade_canal:.2f} bps\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COM O DJIKSTRA DENTRO DO AMBIENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "\n",
    "class UAVCommunicationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, num_uavs=num_drones, area_size=(100, 90)):\n",
    "        super().__init__()\n",
    "        self.num_uavs = num_uavs\n",
    "        self.area_size = area_size\n",
    "        self.posicoes = posicoes.copy()\n",
    "        self.posicao_jammer = posicao_jammer\n",
    "        self.ultimo_info = {}\n",
    "\n",
    "        # Define o espaço de ação: direções das antenas + deslocamentos x e y\n",
    "        self.action_space = spaces.Box(low=np.array([0]*num_uavs + [-40]*num_uavs + [-40]*num_uavs), \n",
    "                                       high=np.array([360]*num_uavs + [40]*num_uavs + [40]*num_uavs), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=0, high=360, shape=(num_uavs,), dtype=np.float32)\n",
    "\n",
    "        self.direcoes_antena = np.random.uniform(0, 360, size=num_uavs)\n",
    "        self.capacidades = []  # Inicializa a lista de capacidades para normalização\n",
    "        self.subgrade_size=subgrade_size\n",
    "        self.subgrade_start=subgrade_start\n",
    "        self.ganhos_df=ganhos_df\n",
    "\n",
    "    def step(self, action):\n",
    "        direcoes_antena = action[:self.num_uavs]\n",
    "        movimentos_x = action[self.num_uavs:2*self.num_uavs]\n",
    "        movimentos_y = action[2*self.num_uavs:]\n",
    "\n",
    "        self.direcoes_antena = np.array(direcoes_antena)\n",
    "        \n",
    "        for i in range(self.num_uavs):\n",
    "            nova_pos_x = self.posicoes[i][0] + movimentos_x[i]\n",
    "            nova_pos_y = self.posicoes[i][1] + movimentos_y[i]\n",
    "            nova_pos_x = min(max(nova_pos_x, subgrade_start[0]), subgrade_start[0] + subgrade_size[0])\n",
    "            nova_pos_y = min(max(nova_pos_y, subgrade_start[1]), subgrade_start[1] + subgrade_size[1])\n",
    "            self.posicoes[i] = np.array([nova_pos_x, nova_pos_y])\n",
    "\n",
    "        capacidades_por_link = []\n",
    "\n",
    "        for i in range(self.posicoes.shape[0]):\n",
    "            for j in range(self.posicoes.shape[0]):\n",
    "                if i != j:\n",
    "                    d = distancia(self.posicoes[i], self.posicoes[j])\n",
    "                    ganho_transmissao, ganho_rececao = calcula_ganhos(self.posicoes, self.direcoes_antena, i, j, ganhos_df)\n",
    "                    potencia_recebida = calcula_potencia_recebida(Ptx_dBm, ganho_transmissao, ganho_rececao, d, lambda_m)\n",
    "                    potencia_ruido = calcula_potencia_jammer(self.posicoes[j], self.direcoes_antena[j], self.posicao_jammer, potencia_jammer_dBm, ganhos_df)\n",
    "                    capacidade_canal = calcula_capacidade(potencia_recebida, potencia_ruido)\n",
    "                    capacidades_por_link.append(capacidade_canal)\n",
    "\n",
    "        capacidade_media = np.mean(capacidades_por_link)\n",
    "        capacidade_minima = np.min(capacidades_por_link)\n",
    "\n",
    "        self.capacidades.extend(capacidades_por_link)\n",
    "        if len(self.capacidades) > 1000:\n",
    "            self.capacidades = self.capacidades[-1000:]\n",
    "\n",
    "        min_capacidade = np.min(self.capacidades)\n",
    "        max_capacidade = np.max(self.capacidades)\n",
    "        # capacidade_media_normalizada = (capacidade_media - min_capacidade) / (max_capacidade - min_capacidade + 1e-6)\n",
    "        # capacidade_minima_normalizada = (capacidade_minima - min_capacidade) / (max_capacidade - min_capacidade + 1e-6)\n",
    "\n",
    "        G = nx.Graph()\n",
    "        num_drones = self.posicoes.shape[0]\n",
    "        capacidade_matriz = np.zeros((self.num_uavs, self.num_uavs))\n",
    "        link_index = 0\n",
    "\n",
    "        for i in range(self.num_uavs):\n",
    "            for j in range(self.num_uavs):\n",
    "                if i != j:\n",
    "                    capacidade_matriz[i, j] = capacidades_por_link[link_index]\n",
    "                    link_index += 1\n",
    "\n",
    "        for i in range(num_drones):\n",
    "            for j in range(i + 1, num_drones):\n",
    "                capacidade = capacidade_matriz[i, j]\n",
    "                G.add_edge(i, j, weight=1.0 / capacidade)\n",
    "\n",
    "        bottlenecks = {}\n",
    "        for i in range(num_drones):\n",
    "            for j in range(num_drones):\n",
    "                if i != j:\n",
    "                    try:\n",
    "                        caminho = nx.dijkstra_path(G, source=i, target=j, weight='weight')\n",
    "                        menor_capacidade = float('inf')\n",
    "                        for k in range(len(caminho) - 1):\n",
    "                            cap_atual = capacidade_matriz[caminho[k], caminho[k+1]]\n",
    "                            if cap_atual < menor_capacidade:\n",
    "                                menor_capacidade = cap_atual\n",
    "                        bottlenecks[(i, j)] = (caminho, menor_capacidade)\n",
    "                    except nx.NetworkXNoPath:\n",
    "                        print(f\"Não há caminho do nó {i} para o nó {j}\")\n",
    "\n",
    "        capacidade_bottleneck_media = np.mean([bottleneck for caminho, bottleneck in bottlenecks.values()])\n",
    "        capacidade_bottleneck_minima = np.min([bottleneck for caminho, bottleneck in bottlenecks.values()])\n",
    "\n",
    "        # capacidade_bottleneck_media_normalizada = (capacidade_bottleneck_media - min_capacidade) / (max_capacidade - min_capacidade + 1e-6)\n",
    "        # capacidade_bottleneck_minima_normalizada = (capacidade_bottleneck_minima - min_capacidade) / (max_capacidade - min_capacidade + 1e-6)\n",
    "\n",
    "        distancia_jammer = np.mean([distancia(pos, self.posicao_jammer) for pos in self.posicoes])\n",
    "        penalidade_distancia_jammer = -(distancia_jammer ** 2)  # Ajustado para escala apropriada\n",
    "\n",
    "        distancias_entre_drones = [distancia(self.posicoes[i], self.posicoes[j]) for i in range(num_drones) for j in range(i+1, num_drones)]\n",
    "        distancia_minima_entre_drones = np.min(distancias_entre_drones)\n",
    "        penalidade_proximidade_drones = (max(0, (30 - distancia_minima_entre_drones) ** 2))  # Ajustado para escala apropriada\n",
    "\n",
    "        # Ajuste da função de recompensa para refletir as penalidades não normalizadas\n",
    "        recompensa = capacidade_media * capacidade_bottleneck_minima - ( 0 * penalidade_distancia_jammer + 0 * penalidade_proximidade_drones)\n",
    "\n",
    "        capacidades_por_link = [round(capacidade, 3) for capacidade in capacidades_por_link]\n",
    "        capacidade_media = round(capacidade_media, 3)\n",
    "\n",
    "        info = {\n",
    "            'Recompensa': recompensa,\n",
    "            'Capacidade média [Kbps]': capacidade_media,\n",
    "            'Capacidades_por_link [Kbps]': capacidades_por_link,\n",
    "            'Matriz de Capacidades [Kbps]': capacidade_matriz,\n",
    "            'Capacidade mínima [Kbps]': capacidade_minima,\n",
    "            # 'Capacidade média normalizada': capacidade_media_normalizada,\n",
    "            # 'Capacidade mínima normalizada': capacidade_minima_normalizada,\n",
    "            'Capacidade bottleneck média': capacidade_bottleneck_media,\n",
    "            'Capacidade bottleneck mínima': capacidade_bottleneck_minima,\n",
    "            # 'Capacidade bottleneck média normalizada': capacidade_bottleneck_media_normalizada,\n",
    "            # 'Capacidade bottleneck mínima normalizada': capacidade_bottleneck_minima_normalizada,\n",
    "            'Penalidade distância ao jammer': penalidade_distancia_jammer,\n",
    "            'Penalidade proximidade entre drones': penalidade_proximidade_drones\n",
    "        }\n",
    "\n",
    "        done = False\n",
    "        return np.array(self.direcoes_antena), recompensa, done, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        sns.set(style=\"whitegrid\")\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        subgrade_start = self.subgrade_start\n",
    "        subgrade_size = self.subgrade_size\n",
    "        resolution = 5\n",
    "\n",
    "        rect = plt.Rectangle(subgrade_start, subgrade_size[0], subgrade_size[1], linewidth=1, edgecolor='blue', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Desenhar linhas verticais da subgrade dentro do limite da área\n",
    "        for x in np.arange(subgrade_start[0], subgrade_start[0] + subgrade_size[0] + resolution, resolution):\n",
    "            ax.axvline(x, color='blue', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        # Desenhar linhas horizontais da subgrade dentro do limite da área\n",
    "        for y in np.arange(subgrade_start[1], subgrade_start[1] + subgrade_size[1] + resolution, resolution):\n",
    "            ax.axhline(y, color='blue', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        # Desenhar os drones\n",
    "        for i, pos in enumerate(self.posicoes):\n",
    "            ax.scatter(pos[0], pos[1], color='blue', s=100, label='Drone' if i == 0 else \"\")\n",
    "            ax.text(pos[0], pos[1] - 2, f'{i}', horizontalalignment='center', color='white', fontweight='bold')\n",
    "\n",
    "\n",
    "        angulos = np.deg2rad(self.ganhos_df['angulo'])\n",
    "        ganhos = self.ganhos_df['ganho']\n",
    "\n",
    "        # Normalizar os ganhos para o intervalo [0, 1]\n",
    "        ganhos_normalizados = (ganhos - ganhos.min()) / (ganhos.max() - ganhos.min())\n",
    "\n",
    "        # Desenhar o diagrama de radiação sem adicionar ao gráfico principal\n",
    "        direcao = self.direcoes_antena[0]\n",
    "        angulos_rotacionados = angulos + np.deg2rad(direcao)\n",
    "        escala = 6  # Ajuste este valor conforme necessário\n",
    "        contorno_x = ganhos_normalizados * np.cos(angulos_rotacionados) * escala\n",
    "        contorno_y = ganhos_normalizados * np.sin(angulos_rotacionados) * escala\n",
    "\n",
    "        for i, (x, y) in enumerate(self.posicoes):\n",
    "            direcao = self.direcoes_antena[i]\n",
    "            angulos_rotacionados = angulos + np.deg2rad(direcao)\n",
    "            contorno_x = x + ganhos_normalizados * np.cos(angulos_rotacionados) * escala\n",
    "            contorno_y = y + ganhos_normalizados * np.sin(angulos_rotacionados) * escala\n",
    "            ax.plot(contorno_x, contorno_y, color='blue', alpha=0.7)\n",
    "\n",
    "        ax.scatter(self.posicao_jammer[0], self.posicao_jammer[1], color='red', s=100, marker='o', label='Jammer')\n",
    "\n",
    "        class CustomHandlerPatch(HandlerPatch):\n",
    "            def create_artists(self, legend, orig_handle, xdescent, ydescent, width, height, fontsize, trans):\n",
    "                offset_x = width * 0.3  # Ajuste este valor para mover o patch para a direita\n",
    "                offset_y = ydescent - height * 0.5\n",
    "                patch = patches.Polygon(\n",
    "                    np.column_stack((ganhos_normalizados * np.cos(angulos) * escala * 2.5 + offset_x, ganhos_normalizados * np.sin(angulos) * escala * 1.8)), \n",
    "                    closed=True, color='blue', alpha=0.9, transform=trans\n",
    "                )\n",
    "                return [patch]\n",
    "\n",
    "        custom_patch = patches.Patch(color='blue', label='Diagrama de Radiação')\n",
    "\n",
    "        # Adicionar a legenda\n",
    "        handles = [\n",
    "            mlines.Line2D([], [], color='blue', marker='o', linestyle='None', markersize=10, label='Drone'),\n",
    "            mlines.Line2D([], [], color='red', marker='o', linestyle='None', markersize=10, label='Jammer'),\n",
    "            custom_patch\n",
    "        ]\n",
    "        \n",
    "        for i, pos in enumerate(self.posicoes):\n",
    "            handles.append(\n",
    "                mlines.Line2D([], [], color='blue', marker='', linestyle='None', markersize=10,\n",
    "                            label=f'Drone {i}: Pos ({pos[0]}, {pos[1]}), Dir {self.direcoes_antena[i]:.1f}°')\n",
    "            )\n",
    "        \n",
    "        handles.append(\n",
    "            mlines.Line2D([], [], color='none', marker='', linestyle='None', markersize=0,\n",
    "                        label=f'Capacidade Média [bps]: {cap_media:.2f}')\n",
    "        )\n",
    "        handles.append(\n",
    "            mlines.Line2D([], [], color='none', marker='', linestyle='None', markersize=0,\n",
    "                        label=f'Bottleneck Mínimo [bps]: {bottleneck:.2f}')\n",
    "        )\n",
    "        \n",
    "        # Ajuste do tamanho da legenda com fontsize e disposição horizontal\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fontsize='small', ncol=3, handles=handles, handler_map={custom_patch: CustomHandlerPatch()})\n",
    "        # ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='small',borderpad=1, handles=handles, handler_map={custom_patch: CustomHandlerPatch(), (None, None): HandlerTuple()})\n",
    "        \n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_xlim(0, self.area_size[0])\n",
    "        ax.set_ylim(0, self.area_size[1])\n",
    "        ax.set_yticks(np.arange(0, self.area_size[1] + 1, 20))\n",
    "    \n",
    "        plt.title(title)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def reset(self,seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        self.direcoes_antena = np.random.uniform(0, 360, size=self.num_uavs)\n",
    "        self.posicoes = posicoes.copy()\n",
    "        obs = np.array(self.direcoes_antena)\n",
    "        return obs, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALGORITMO GENETICO\n",
    "\n",
    "1.Tamanho da População:\n",
    "\n",
    "    Maior: Uma população maior oferece uma diversidade genética mais ampla, o que pode ajudar a evitar mínimos locais, mas também aumenta o custo computacional.\n",
    "    Menor: Uma população menor pode levar a uma convergência mais rápida, mas pode ficar presa em mínimos locais.\n",
    "\n",
    "2.Taxa de Mutação:\n",
    "\n",
    "    Alta: Uma taxa de mutação mais alta aumenta a diversidade genética dentro da população e pode ajudar a sair de mínimos locais. No entanto, se for muito alta, pode causar uma busca aleatória, reduzindo a eficiência do algoritmo.\n",
    "    Baixa: Uma taxa de mutação baixa mantém a estabilidade da população, mas pode resultar em convergência prematura para soluções subótimas.\n",
    "\n",
    "3.Taxa de Cruzamento:\n",
    "\n",
    "    Alta: Promove a combinação de características de diferentes indivíduos, potencialmente levando a uma melhoria mais rápida.\n",
    "    Baixa: Reduz a probabilidade de alterar boas soluções, mas pode limitar a capacidade do algoritmo de explorar novas e potencialmente melhores áreas do espaço de busca.\n",
    "\n",
    "4.Número de Gerações:\n",
    "\n",
    "    Maior número de gerações: Permite mais iterações do processo de seleção, cruzamento e mutação, dando mais tempo para a população evoluir.\n",
    "    Menor número de gerações: Pode ser suficiente se a convergência for rápida, mas corre o risco de não permitir desenvolvimento suficiente, especialmente com uma taxa de mutação baixa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALGORITMO GENETICO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm:\n",
    "    def __init__(self, env, grid_points, population_size=500, generations=100, mutation_rate=0.2, crossover_rate=0.9):\n",
    "        self.env = env\n",
    "        self.grid_points = grid_points\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "\n",
    "        self.population = [self.random_chromosome() for _ in range(population_size)]\n",
    "\n",
    "    def random_chromosome(self):\n",
    "        indices = np.random.choice(len(self.grid_points), size=self.env.num_uavs, replace=False)\n",
    "        positions = self.grid_points[indices].flatten()\n",
    "        directions = np.random.uniform(0, 360, size=self.env.num_uavs)\n",
    "        return np.concatenate([positions, directions])\n",
    "\n",
    "    def evaluate_fitness(self, chromosome):\n",
    "        positions = chromosome[:2*self.env.num_uavs].reshape(self.env.num_uavs, 2)\n",
    "        directions = chromosome[2*self.env.num_uavs:]\n",
    "        self.env.posicoes = positions\n",
    "        self.env.direcoes_antena = directions\n",
    "        obs, reward, done, info = self.env.step(np.concatenate([directions, np.zeros(self.env.num_uavs), np.zeros(self.env.num_uavs)]))\n",
    "        return reward, info\n",
    "\n",
    "    def select(self):\n",
    "        tournament_size = 5\n",
    "        selected = []\n",
    "        fitness_scores = [self.evaluate_fitness(chrom) for chrom in self.population]\n",
    "        for _ in range(self.population_size):\n",
    "            contenders = random.sample(list(enumerate(fitness_scores)), tournament_size)\n",
    "            winner_index = max(contenders, key=lambda item: item[1][0])[0]\n",
    "            selected.append(self.population[winner_index])\n",
    "        return selected\n",
    "\n",
    "    def crossover(self, parent1, parent2):\n",
    "        if random.random() < self.crossover_rate:\n",
    "            point = random.randint(1, len(parent1) - 1)\n",
    "            child1 = np.concatenate([parent1[:point], parent2[point:]])\n",
    "            child2 = np.concatenate([parent2[:point], parent1[point:]])\n",
    "            return self.ensure_unique_positions(child1), self.ensure_unique_positions(child2)\n",
    "        else:\n",
    "            return parent1, parent2\n",
    "\n",
    "    def mutate(self, chromosome):\n",
    "        num_genes = len(chromosome)\n",
    "        positions = chromosome[:2*self.env.num_uavs].reshape(self.env.num_uavs, 2)\n",
    "        directions = chromosome[2*self.env.num_uavs:]\n",
    "\n",
    "        for i in range(self.env.num_uavs):\n",
    "            if random.random() < self.mutation_rate:\n",
    "                new_pos_index = np.random.choice(len(self.grid_points))\n",
    "                while any(np.array_equal(self.grid_points[new_pos_index], positions[j]) for j in range(self.env.num_uavs)):\n",
    "                    new_pos_index = np.random.choice(len(self.grid_points))\n",
    "                positions[i] = self.grid_points[new_pos_index]\n",
    "\n",
    "        for i in range(len(directions)):\n",
    "            if random.random() < self.mutation_rate:\n",
    "                mutation = random.uniform(-90, 90)\n",
    "                directions[i] = (directions[i] + mutation) % 360\n",
    "\n",
    "        return np.concatenate([positions.flatten(), directions])\n",
    "\n",
    "    def ensure_unique_positions(self, chromosome):\n",
    "        positions = chromosome[:2*self.env.num_uavs].reshape(self.env.num_uavs, 2)\n",
    "        unique_positions = []\n",
    "        for pos in positions:\n",
    "            while any(np.array_equal(pos, upos) for upos in unique_positions):\n",
    "                new_pos_index = np.random.choice(len(self.grid_points))\n",
    "                pos = self.grid_points[new_pos_index]\n",
    "            unique_positions.append(pos)\n",
    "        return np.concatenate([np.array(unique_positions).flatten(), chromosome[2*self.env.num_uavs:]])\n",
    "\n",
    "    def run(self):\n",
    "        best_fitness_ever = -np.inf  # Armazenar o melhor fitness encontrado\n",
    "        best_solution_ever = None    # Armazenar a melhor solução encontrada\n",
    "        best_info_ever = None        # Armazenar a melhor info correspondente ao melhor fitness\n",
    "\n",
    "        for generation in range(self.generations):\n",
    "            new_population = []\n",
    "            parents = self.select()\n",
    "            \n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = random.sample(parents, 2)\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                new_population.extend([self.mutate(child1), self.mutate(child2)])\n",
    "            \n",
    "            self.population = new_population[:self.population_size]\n",
    "            fitness_scores = [self.evaluate_fitness(chrom) for chrom in self.population]\n",
    "            \n",
    "            # Encontrar o melhor fitness e sua informação na geração atual\n",
    "            best_fitness_in_gen, best_info_in_gen = max(fitness_scores, key=lambda x: x[0])\n",
    "            \n",
    "            # Verificar se este é o melhor fitness de todas as gerações\n",
    "            if best_fitness_in_gen > best_fitness_ever:\n",
    "                best_fitness_ever = best_fitness_in_gen\n",
    "                best_solution_ever = self.population[fitness_scores.index((best_fitness_in_gen, best_info_in_gen))]\n",
    "                best_info_ever = best_info_in_gen\n",
    "                \n",
    "            print(f\"Generation {generation}: Best Fitness = {best_fitness_in_gen:.2f}\")\n",
    "        \n",
    "        # Retornar a melhor solução e informação encontradas em todas as gerações\n",
    "        return best_solution_ever, best_info_ever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRER O ALGORITMO GENETICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configuração do ambiente e execução do algoritmo genético\n",
    "# env = UAVCommunicationEnv()\n",
    "\n",
    "# # Criar uma instância do Algoritmo Genético\n",
    "# ga = GeneticAlgorithm(env, grid_points)\n",
    "\n",
    "# # Executar o algoritmo e obter a melhor solução e informações\n",
    "# best_solution_genetico, best_info_genetico = ga.run()\n",
    "\n",
    "# # Renderizar a melhor solução encontrada\n",
    "# title = 'Direções e Posições Estabelecidas - Algoritmo Genético'\n",
    "# bottleneck = best_info_genetico['Capacidade bottleneck mínima']\n",
    "# cap_media = best_info_genetico['Capacidade média [Kbps]']\n",
    "\n",
    "# # Atualizar o ambiente com a melhor solução antes de renderizar\n",
    "# env.direcoes_antena = best_solution_genetico\n",
    "# env.render()\n",
    "\n",
    "# # Imprimir detalhes da melhor solução encontrada\n",
    "# print(\"\\nRecompensa:\", best_info_genetico['Recompensa'])\n",
    "# print(\"\\nCapacidade Média:\", best_info_genetico['Capacidade média [Kbps]']) \n",
    "# print(\"\\nCapacidade bottleneck mínima:\", best_info_genetico['Capacidade bottleneck mínima'])  \n",
    "# print(\"\\nCapacidade bottleneck média:\", best_info_genetico['Capacidade bottleneck média'])\n",
    "# print(\"\\nCapacidade por Link:\", best_info_genetico['Capacidades_por_link [Kbps]'])\n",
    "# print(\"\\nMatriz de Capacidades:\", '\\n'.join(['\\t' + ' '.join(f\"{item:.2f}\" for item in row) for row in best_info_genetico['Matriz de Capacidades [Kbps]']]))\n",
    "# capacidade_matriz = best_info_genetico['Matriz de Capacidades [Kbps]']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALG GENETICO ENCAPSULADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm:\n",
    "    def __init__(self, env, grid_points, population_size=100, generations=200, mutation_rate=0.15, crossover_rate=0.9):\n",
    "        self.env = env\n",
    "        self.grid_points = grid_points\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "\n",
    "    def random_position_chromosome(self):\n",
    "        indices = np.random.choice(len(self.grid_points), size=self.env.num_uavs, replace=False)\n",
    "        return self.grid_points[indices].flatten()\n",
    "\n",
    "    def random_direction_chromosome(self):\n",
    "        return np.random.uniform(0, 360, size=self.env.num_uavs)\n",
    "\n",
    "    def evaluate_position_fitness(self, chromosome):\n",
    "        positions = chromosome.reshape(self.env.num_uavs, 2)\n",
    "        self.env.posicoes = positions\n",
    "        directions = np.zeros(self.env.num_uavs)  # Direções fixas ou predefinidas\n",
    "        obs, reward, done, info = self.env.step(np.concatenate([directions, np.zeros(self.env.num_uavs), np.zeros(self.env.num_uavs)]))\n",
    "        return reward, info\n",
    "\n",
    "    def evaluate_direction_fitness(self, directions):\n",
    "        self.env.direcoes_antena = directions\n",
    "        obs, reward, done, info = self.env.step(np.concatenate([directions, np.zeros(self.env.num_uavs), np.zeros(self.env.num_uavs)]))\n",
    "        return reward, info\n",
    "\n",
    "    def select(self, population, fitness_scores):\n",
    "        tournament_size = 5\n",
    "        selected = []\n",
    "        for _ in range(self.population_size):\n",
    "            contenders = random.sample(list(enumerate(fitness_scores)), tournament_size)\n",
    "            winner_index = max(contenders, key=lambda item: item[1][0])[0]\n",
    "            selected.append(population[winner_index])\n",
    "        return selected\n",
    "\n",
    "    def crossover_positions(self, parent1, parent2):\n",
    "        if random.random() < self.crossover_rate:\n",
    "            point = random.randint(1, len(parent1) - 1)\n",
    "            child1 = np.concatenate([parent1[:point], parent2[point:]])\n",
    "            child2 = np.concatenate([parent2[:point], parent1[point:]])\n",
    "            return self.ensure_unique_positions(child1), self.ensure_unique_positions(child2)\n",
    "        else:\n",
    "            return parent1, parent2\n",
    "\n",
    "    def crossover_directions(self, parent1, parent2):\n",
    "        if random.random() < self.crossover_rate:\n",
    "            point = random.randint(1, len(parent1) - 1)\n",
    "            child1 = np.concatenate([parent1[:point], parent2[point:]])\n",
    "            child2 = np.concatenate([parent2[:point], parent1[point:]])\n",
    "            return child1, child2\n",
    "        else:\n",
    "            return parent1, parent2\n",
    "\n",
    "    def mutate_positions(self, chromosome):\n",
    "        positions = chromosome.reshape(self.env.num_uavs, 2)\n",
    "        for i in range(self.env.num_uavs):\n",
    "            if random.random() < self.mutation_rate:\n",
    "                new_pos_index = np.random.choice(len(self.grid_points))\n",
    "                while any(np.array_equal(self.grid_points[new_pos_index], positions[j]) for j in range(self.env.num_uavs)):\n",
    "                    new_pos_index = np.random.choice(len(self.grid_points))\n",
    "                positions[i] = self.grid_points[new_pos_index]\n",
    "        return positions.flatten()\n",
    "\n",
    "    def mutate_directions(self, directions):\n",
    "        for i in range(len(directions)):\n",
    "            if random.random() < self.mutation_rate:\n",
    "                mutation = random.uniform(-90, 90)\n",
    "                directions[i] = (directions[i] + mutation) % 360\n",
    "        return directions\n",
    "\n",
    "    def ensure_unique_positions(self, chromosome):\n",
    "        positions = chromosome.reshape(self.env.num_uavs, 2)\n",
    "        unique_positions = []\n",
    "        for pos in positions:\n",
    "            while any(np.array_equal(pos, upos) for upos in unique_positions):\n",
    "                new_pos_index = np.random.choice(len(self.grid_points))\n",
    "                pos = self.grid_points[new_pos_index]\n",
    "            unique_positions.append(pos)\n",
    "        return np.array(unique_positions).flatten()\n",
    "\n",
    "    def run_position_optimization(self):\n",
    "        best_fitness_ever = -np.inf\n",
    "        best_positions_ever = None\n",
    "        best_info_ever = None\n",
    "        fitness_history_positions = []  # Para armazenar a evolução da recompensa\n",
    "\n",
    "        population = [self.random_position_chromosome() for _ in range(self.population_size)]\n",
    "\n",
    "        for generation in range(self.generations):\n",
    "            fitness_scores = [self.evaluate_position_fitness(chrom) for chrom in population]\n",
    "            best_fitness_in_gen, best_info_in_gen = max(fitness_scores, key=lambda x: x[0])\n",
    "            fitness_history_positions.append(best_fitness_in_gen)  # Armazena a melhor recompensa de cada geração\n",
    "\n",
    "            if best_fitness_in_gen > best_fitness_ever:\n",
    "                best_fitness_ever = best_fitness_in_gen\n",
    "                best_positions_ever = population[fitness_scores.index((best_fitness_in_gen, best_info_in_gen))]\n",
    "                best_info_ever = best_info_in_gen\n",
    "\n",
    "            selected = self.select(population, fitness_scores)\n",
    "            new_population = []\n",
    "\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = random.sample(selected, 2)\n",
    "                child1, child2 = self.crossover_positions(parent1, parent2)\n",
    "                new_population.extend([self.mutate_positions(child1), self.mutate_positions(child2)])\n",
    "\n",
    "            population = new_population[:self.population_size]\n",
    "            print(f\"Generation {generation}: Best Fitness = {best_fitness_in_gen:.2f}\")\n",
    "\n",
    "        # Plotar evolução da recompensa durante a otimização de posição\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(fitness_history_positions, marker='o', linestyle='-', color='b', label='Best Fitness - Positions')\n",
    "        plt.title('')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        return best_positions_ever, best_info_ever, fitness_history_positions\n",
    "\n",
    "    def run_direction_optimization(self, best_positions):\n",
    "        best_fitness_ever = -np.inf\n",
    "        best_directions_ever = None\n",
    "        best_info_ever = None\n",
    "        fitness_history_directions = []  # Para armazenar a evolução da recompensa\n",
    "\n",
    "        population = [self.random_direction_chromosome() for _ in range(self.population_size)]\n",
    "\n",
    "        for generation in range(self.generations):\n",
    "            fitness_scores = [self.evaluate_direction_fitness(chrom) for chrom in population]\n",
    "            best_fitness_in_gen, best_info_in_gen = max(fitness_scores, key=lambda x: x[0])\n",
    "            fitness_history_directions.append(best_fitness_in_gen)  # Armazena a melhor recompensa de cada geração\n",
    "\n",
    "            if best_fitness_in_gen > best_fitness_ever:\n",
    "                best_fitness_ever = best_fitness_in_gen\n",
    "                best_directions_ever = population[fitness_scores.index((best_fitness_in_gen, best_info_in_gen))]\n",
    "                best_info_ever = best_info_in_gen\n",
    "\n",
    "            selected = self.select(population, fitness_scores)\n",
    "            new_population = []\n",
    "\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = random.sample(selected, 2)\n",
    "                child1, child2 = self.crossover_directions(parent1, parent2)\n",
    "                new_population.extend([self.mutate_directions(child1), self.mutate_directions(child2)])\n",
    "\n",
    "            population = new_population[:self.population_size]\n",
    "            print(f\"Generation {generation}: Best Fitness = {best_fitness_in_gen:.2f}\")\n",
    "\n",
    "        # Plotar evolução da recompensa durante a otimização de direção\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(fitness_history_directions, marker='o', linestyle='-', color='g', label='Best Fitness - Directions')\n",
    "        plt.axhline(y=1587, color='orange', linestyle='-', label='Best Fitness - Omnidirectional')\n",
    "        plt.title('')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        return best_directions_ever, best_info_ever, fitness_history_directions\n",
    "\n",
    "# Exemplo de uso do algoritmo dividido em duas fases\n",
    "env = UAVCommunicationEnv()\n",
    "\n",
    "# Criar uma instância do Algoritmo Genético\n",
    "ga = GeneticAlgorithm(env, grid_points)\n",
    "\n",
    "env.posicao_jammer=[65,40]\n",
    "\n",
    "env.posicoes=np.array([\n",
    "    [135, 25],  # Posição do Drone 1\n",
    "    [150, 25],  # Posição do Drone 2\n",
    "    [130, 25],  # Posição do Drone 3\n",
    "    [125, 25]   # Posição do Drone 4\n",
    "])\n",
    "\n",
    "env.subgrade_start=[80,20]\n",
    "\n",
    "\n",
    "\n",
    "# Fase 1: Otimização das Posições\n",
    "print('---------------------------Descobrir Posições------------------------------')\n",
    "best_positions, _, fitness_history_positions = ga.run_position_optimization()\n",
    "\n",
    "print(best_positions)\n",
    "\n",
    "\n",
    "best_positions=np.array([\n",
    "    [135, 25],  # Posição do Drone 1\n",
    "    [150, 25],  # Posição do Drone 2\n",
    "    [130, 25],  # Posição do Drone 3\n",
    "    [125, 25]   # Posição do Drone 4\n",
    "])\n",
    "\n",
    "# Atualizar as melhores posições no ambiente\n",
    "env.posicoes = best_positions.reshape(env.num_uavs, 2)\n",
    "\n",
    "# Fase 2: Otimização das Direções\n",
    "print('---------------------------Descobrir Direções------------------------------')\n",
    "best_directions, best_info, fitness_history_directions = ga.run_direction_optimization(best_positions)\n",
    "print(best_directions)\n",
    "\n",
    "# best_directions=np.array([293,41,167,168])\n",
    "\n",
    "# Atualizar as melhores direções no ambiente\n",
    "env.direcoes_antena = best_directions\n",
    "env.posicoes=best_positions\n",
    "\n",
    "# Renderizar a melhor solução encontrada\n",
    "title = 'Direções e Posições Estabelecidas - Algoritmo SAC'\n",
    "bottleneck = best_info['Capacidade bottleneck mínima']\n",
    "cap_media = best_info['Capacidade média [Kbps]']\n",
    "env.render()\n",
    "\n",
    "# Imprimir detalhes da melhor solução encontrada\n",
    "print(\"\\nRecompensa:\", best_info['Recompensa'])\n",
    "print(\"\\nCapacidade Média:\", best_info['Capacidade média [Kbps]']) \n",
    "print(\"\\nCapacidade bottleneck mínima:\", best_info['Capacidade bottleneck mínima'])  \n",
    "print(\"\\nCapacidade bottleneck média:\", best_info['Capacidade bottleneck média'])\n",
    "print(\"\\nCapacidade por Link:\", best_info['Capacidades_por_link [Kbps]'])\n",
    "print(\"\\nMatriz de Capacidades:\", '\\n'.join(['\\t' + ' '.join(f\"{item:.2f}\" for item in row) for row in best_info['Matriz de Capacidades [Kbps]']]))\n",
    "capacidade_matriz = best_info['Matriz de Capacidades [Kbps]']\n",
    "\n",
    "\n",
    "# Plotar gráfico combinado\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fitness_history_positions, marker='o', linestyle='-', color='b', label='Best Fitness - Positions')\n",
    "plt.plot(fitness_history_directions, marker='o', linestyle='-', color='g', label='Best Fitness - Directions')\n",
    "plt.title('')\n",
    "plt.xlabel('Generations')\n",
    "plt.ylabel('')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def generate_unique_positions(num_uavs, subgrade_start, subgrade_size, resolution):\n",
    "    x_values = np.arange(subgrade_start[0], subgrade_start[0] + subgrade_size[0], resolution)\n",
    "    y_values = np.arange(subgrade_start[1], subgrade_start[1] + subgrade_size[1], resolution)\n",
    "    possible_positions = np.array(np.meshgrid(x_values, y_values)).T.reshape(-1, 2)\n",
    "    \n",
    "    # Escolher posições aleatórias únicas\n",
    "    indices = np.random.choice(len(possible_positions), size=num_drones, replace=False)\n",
    "    chosen_positions = possible_positions[indices]\n",
    "    \n",
    "    # print(\"Chosen positions:\", chosen_positions)  # Adicionado para depuração\n",
    "    \n",
    "    return chosen_positions\n",
    "\n",
    "\n",
    "\n",
    "class UAVCommunicationEnv_PPO(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, num_uavs=num_drones, area_size=(100, 90)):\n",
    "        super().__init__()\n",
    "        self.num_uavs = num_uavs\n",
    "        self.area_size = area_size\n",
    "        self.posicoes = posicoes\n",
    "        self.posicao_jammer = posicao_jammer\n",
    "        self.ultimo_info = {}\n",
    "\n",
    "        # Define o espaço de ação: direções das antenas + deslocamentos x e y\n",
    "        self.action_space = spaces.Box(low=np.array([0]*num_uavs + [-40]*num_uavs + [-40]*num_uavs), \n",
    "                                       high=np.array([360]*num_uavs + [40]*num_uavs + [40]*num_uavs), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=0, high=360, shape=(num_uavs,), dtype=np.float32)\n",
    "\n",
    "        self.direcoes_antena = np.random.uniform(0, 360, size=num_uavs)\n",
    "        self.capacidades = []  # Inicializa a lista de capacidades para normalização\n",
    "        self.subgrade_size=subgrade_size\n",
    "        self.subgrade_start=subgrade_start\n",
    "        self.ganhos_df=ganhos_df\n",
    "        self.resolution=resolution\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        if self.posicoes.size == 0:\n",
    "            raise ValueError(\"As posições dos drones não foram inicializadas corretamente.\")\n",
    "        \n",
    "        direcoes_antena = action[:self.num_uavs]\n",
    "        movimentos_x = action[self.num_uavs:2*self.num_uavs]\n",
    "        movimentos_y = action[2*self.num_uavs:]\n",
    "\n",
    "        self.direcoes_antena = np.array(direcoes_antena)\n",
    "\n",
    "        # for i in range(self.num_uavs):\n",
    "        #     # Aplicar deslocamento\n",
    "        #     nova_pos_x = self.posicoes[i][0] + movimentos_x[i]\n",
    "        #     nova_pos_y = self.posicoes[i][1] + movimentos_y[i]\n",
    "\n",
    "        #     # Forçar nova posição ao ponto mais próximo da grelha\n",
    "        #     nova_pos_x = np.round(nova_pos_x / resolution) * resolution\n",
    "        #     nova_pos_y = np.round(nova_pos_y / resolution) * resolution\n",
    "\n",
    "        #     # Garantir que a nova posição está dentro da subgrade\n",
    "        #     nova_pos_x = min(max(nova_pos_x, subgrade_start[0]), subgrade_start[0] + subgrade_size[0] - resolution)\n",
    "        #     nova_pos_y = min(max(nova_pos_y, subgrade_start[1]), subgrade_start[1] + subgrade_size[1] - resolution)\n",
    "\n",
    "        #     self.posicoes[i] = np.array([nova_pos_x, nova_pos_y])\n",
    "\n",
    "        \n",
    "        # Verificar e corrigir duplicações de posições\n",
    "        unique_positions, indices = np.unique(self.posicoes, axis=0, return_index=True)\n",
    "        if len(unique_positions) < len(self.posicoes):\n",
    "            for i in range(len(self.posicoes)):\n",
    "                if i not in indices:\n",
    "                    # Se houver duplicatas, gerar uma nova posição válida\n",
    "                    new_pos = generate_unique_positions(1, self.subgrade_start, self.subgrade_size, self.resolution)[0]\n",
    "                    while any(np.array_equal(new_pos, pos) for pos in self.posicoes):\n",
    "                        new_pos = generate_unique_positions(1, self.subgrade_start, self.subgrade_size, self.resolution)[0]\n",
    "                    self.posicoes[i] = new_pos\n",
    "        \n",
    "        capacidades_por_link = []\n",
    "\n",
    "        for i in range(self.posicoes.shape[0]):\n",
    "            for j in range(self.posicoes.shape[0]):\n",
    "                if i != j:\n",
    "                    d = distancia(self.posicoes[i], self.posicoes[j])\n",
    "                    ganho_transmissao, ganho_rececao = calcula_ganhos(self.posicoes, self.direcoes_antena, i, j, ganhos_df)\n",
    "                    potencia_recebida = calcula_potencia_recebida(Ptx_dBm, ganho_transmissao, ganho_rececao, d, lambda_m)\n",
    "                    potencia_ruido = calcula_potencia_jammer(self.posicoes[j], self.direcoes_antena[j], self.posicao_jammer, potencia_jammer_dBm, ganhos_df)\n",
    "                    capacidade_canal = calcula_capacidade(potencia_recebida, potencia_ruido)\n",
    "                    capacidades_por_link.append(capacidade_canal)\n",
    "\n",
    "        capacidade_media = np.mean(capacidades_por_link)\n",
    "        capacidade_minima = np.min(capacidades_por_link)\n",
    "\n",
    "        self.capacidades.extend(capacidades_por_link)\n",
    "        if len(self.capacidades) > 1000:\n",
    "            self.capacidades = self.capacidades[-1000:]\n",
    "\n",
    "        min_capacidade = np.min(self.capacidades)\n",
    "        max_capacidade = np.max(self.capacidades)\n",
    "        # capacidade_media_normalizada = (capacidade_media - min_capacidade) / (max_capacidade - min_capacidade + 1e-6)\n",
    "        # capacidade_minima_normalizada = (capacidade_minima - min_capacidade) / (max_capacidade - min_capacidade + 1e-6)\n",
    "\n",
    "        G = nx.Graph()\n",
    "        num_drones = self.posicoes.shape[0]\n",
    "        capacidade_matriz = np.zeros((self.num_uavs, self.num_uavs))\n",
    "        link_index = 0\n",
    "\n",
    "        for i in range(self.num_uavs):\n",
    "            for j in range(self.num_uavs):\n",
    "                if i != j:\n",
    "                    capacidade_matriz[i, j] = capacidades_por_link[link_index]\n",
    "                    link_index += 1\n",
    "\n",
    "        for i in range(num_drones):\n",
    "            for j in range(i + 1, num_drones):\n",
    "                capacidade = capacidade_matriz[i, j]\n",
    "                G.add_edge(i, j, weight=1.0 / capacidade)\n",
    "\n",
    "        bottlenecks = {}\n",
    "        for i in range(num_drones):\n",
    "            for j in range(num_drones):\n",
    "                if i != j:\n",
    "                    try:\n",
    "                        caminho = nx.dijkstra_path(G, source=i, target=j, weight='weight')\n",
    "                        menor_capacidade = float('inf')\n",
    "                        for k in range(len(caminho) - 1):\n",
    "                            cap_atual = capacidade_matriz[caminho[k], caminho[k+1]]\n",
    "                            if cap_atual < menor_capacidade:\n",
    "                                menor_capacidade = cap_atual\n",
    "                        bottlenecks[(i, j)] = (caminho, menor_capacidade)\n",
    "                    except nx.NetworkXNoPath:\n",
    "                        print(f\"Não há caminho do nó {i} para o nó {j}\")\n",
    "\n",
    "        capacidade_bottleneck_media = np.mean([bottleneck for caminho, bottleneck in bottlenecks.values()])\n",
    "        capacidade_bottleneck_minima = np.min([bottleneck for caminho, bottleneck in bottlenecks.values()])\n",
    "\n",
    "        # capacidade_bottleneck_media_normalizada = (capacidade_bottleneck_media - min_capacidade) / (max_capacidade - min_capacidade + 1e-6)\n",
    "        # capacidade_bottleneck_minima_normalizada = (capacidade_bottleneck_minima - min_capacidade) / (max_capacidade - min_capacidade + 1e-6)\n",
    "\n",
    "        distancia_jammer = np.mean([distancia(pos, self.posicao_jammer) for pos in self.posicoes])\n",
    "        penalidade_distancia_jammer = -(distancia_jammer ** 2)  # Ajustado para escala apropriada\n",
    "\n",
    "        distancias_entre_drones = [distancia(self.posicoes[i], self.posicoes[j]) for i in range(num_drones) for j in range(i+1, num_drones)]\n",
    "        distancia_minima_entre_drones = np.min(distancias_entre_drones)\n",
    "        penalidade_proximidade_drones = (max(0, (30 - distancia_minima_entre_drones) ** 2))  # Ajustado para escala apropriada\n",
    "\n",
    "        # Ajuste da função de recompensa para refletir as penalidades não normalizadas\n",
    "        recompensa = capacidade_media * capacidade_bottleneck_minima \n",
    "\n",
    "        capacidades_por_link = [round(capacidade, 3) for capacidade in capacidades_por_link]\n",
    "        capacidade_media = round(capacidade_media, 3)\n",
    "\n",
    "        info = {\n",
    "            'Recompensa': recompensa,\n",
    "            'Capacidade média [Kbps]': capacidade_media,\n",
    "            'Capacidades_por_link [Kbps]': capacidades_por_link,\n",
    "            'Matriz de Capacidades [Kbps]': capacidade_matriz,\n",
    "            'Capacidade mínima [Kbps]': capacidade_minima,\n",
    "            # 'Capacidade média normalizada': capacidade_media_normalizada,\n",
    "            # 'Capacidade mínima normalizada': capacidade_minima_normalizada,\n",
    "            'Capacidade bottleneck média': capacidade_bottleneck_media,\n",
    "            'Capacidade bottleneck mínima': capacidade_bottleneck_minima,\n",
    "            # 'Capacidade bottleneck média normalizada': capacidade_bottleneck_media_normalizada,\n",
    "            # 'Capacidade bottleneck mínima normalizada': capacidade_bottleneck_minima_normalizada,\n",
    "            'Penalidade distância ao jammer': penalidade_distancia_jammer,\n",
    "            'Penalidade proximidade entre drones': penalidade_proximidade_drones\n",
    "        }\n",
    "\n",
    "        done = False\n",
    "        truncated=False\n",
    "        return np.array(self.direcoes_antena), recompensa, done,truncated, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        sns.set(style=\"whitegrid\")\n",
    "        fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "        subgrade_start = self.subgrade_start\n",
    "        subgrade_size = self.subgrade_size\n",
    "        resolution = 5\n",
    "\n",
    "        # Desenhar subgrade com cores mais intensas e linhas finas\n",
    "        rect = plt.Rectangle(subgrade_start, subgrade_size[0], subgrade_size[1], linewidth=1.5, edgecolor='dodgerblue', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        for x in np.arange(subgrade_start[0], subgrade_start[0] + subgrade_size[0] + resolution, resolution):\n",
    "            ax.axvline(x, color='dodgerblue', linestyle='--', linewidth=0.7, alpha=0.8)\n",
    "        for y in np.arange(subgrade_start[1], subgrade_start[1] + subgrade_size[1] + resolution, resolution):\n",
    "            ax.axhline(y, color='dodgerblue', linestyle='--', linewidth=0.7, alpha=0.8)\n",
    "\n",
    "        # Desenhar os drones com cores distintas\n",
    "        for i, pos in enumerate(self.posicoes):\n",
    "            ax.scatter(pos[0], pos[1], color='dimgray', s=200, edgecolor='white', linewidth=1, label='UAV' if i == 0 else \"\")\n",
    "            ax.text(\n",
    "                pos[0], pos[1] + 0.1,  # Ajuste 0.5 para centralizar o texto verticalmente\n",
    "                f'{i}', \n",
    "                horizontalalignment='center', \n",
    "                verticalalignment='center', \n",
    "                color='white', fontweight='bold'\n",
    "            )\n",
    "\n",
    "        # Desenhar setas para indicar a direção de cada drone\n",
    "        arrow_length = 3  # Comprimento da seta\n",
    "        for i, (x, y) in enumerate(self.posicoes):\n",
    "            direcao = np.deg2rad(self.direcoes_antena[i])  # Converte para radianos\n",
    "            dx = arrow_length * np.cos(direcao)  # Comprimento da seta no eixo X\n",
    "            dy = arrow_length * np.sin(direcao)  # Comprimento da seta no eixo Y\n",
    "            ax.quiver(x, y, dx, dy, angles='xy', scale_units='xy', scale=1, color='dimgray', width=0.003)\n",
    "\n",
    "        # Desenhar o diagrama de radiação usando gradientes\n",
    "        angulos = np.deg2rad(self.ganhos_df['angulo'])\n",
    "        ganhos = self.ganhos_df['ganho']\n",
    "        ganhos_normalizados = (ganhos - ganhos.min()) / (ganhos.max() - ganhos.min())\n",
    "        escala = 6\n",
    "\n",
    "        for i, (x, y) in enumerate(self.posicoes):\n",
    "            direcao = self.direcoes_antena[i]\n",
    "            angulos_rotacionados = angulos + np.deg2rad(direcao)\n",
    "            contorno_x = x + ganhos_normalizados * np.cos(angulos_rotacionados) * escala\n",
    "            contorno_y = y + ganhos_normalizados * np.sin(angulos_rotacionados) * escala\n",
    "            ax.plot(contorno_x, contorno_y, color='dodgerblue', alpha=0.7, linestyle='-', linewidth=1.2)\n",
    "\n",
    "        # Desenhar o jammer com um ícone diferente\n",
    "        ax.scatter(self.posicao_jammer[0], self.posicao_jammer[1], color='red', s=150, marker='X', edgecolor='white', linewidth=1, label='Jammer')\n",
    "\n",
    "        # Melhorar a legenda com um design organizado e mais legível\n",
    "        handles = [\n",
    "            mlines.Line2D([], [], color='dimgray', marker='o', linestyle='None', markersize=10, label='UAV'),\n",
    "            mlines.Line2D([], [], color='red', marker='X', linestyle='None', markersize=10, label='Jammer')\n",
    "        ]\n",
    "        \n",
    "        for i, pos in enumerate(self.posicoes):\n",
    "            handles.append(\n",
    "                mlines.Line2D([], [], color='none', marker='', linestyle='None', markersize=0,\n",
    "                            label=f'UAV {i}: Pos ({pos[0]}, {pos[1]}), Dir {self.direcoes_antena[i]:.1f}°')\n",
    "            )\n",
    "\n",
    "        # Informações adicionais na legenda\n",
    "        handles.append(\n",
    "            mlines.Line2D([], [], color='none', marker='', linestyle='None', markersize=0,\n",
    "                        label=f'Average Capacity [bps]: {cap_media:.2f}')\n",
    "        )\n",
    "        handles.append(\n",
    "            mlines.Line2D([], [], color='none', marker='', linestyle='None', markersize=0,\n",
    "                        label=f'Bottleneck [bps]: {bottleneck:.2f}')\n",
    "        )\n",
    "        \n",
    "        # Configurar a legenda de forma elegante fora da área de plotagem\n",
    "        ax.legend(\n",
    "            loc='upper center', \n",
    "            bbox_to_anchor=(0.5, -0.08),  # Ajuste a altura para -0.2\n",
    "            # fontsize='small', \n",
    "            ncol=3,  # Aumenta o número de colunas para que a legenda ocupe mais espaço horizontal\n",
    "            handles=handles, \n",
    "            frameon=True,  # Adicionar borda à legenda para uma aparência mais organizada\n",
    "            framealpha=0.8,  # Ajusta a transparência da borda da legenda\n",
    "            fancybox=True,  # Borda arredondada na legenda\n",
    "            borderpad=1,  # Aumenta o espaçamento interno da legenda\n",
    "            columnspacing=2.0,  # Aumenta o espaçamento entre as colunas da legenda\n",
    "            handletextpad=1.5  # Aumenta o espaçamento entre os marcadores e o texto\n",
    "        )\n",
    "        \n",
    "        # Configurar eixos e título\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "\n",
    "        # Definir uma margem de expansão/deslocamento para o eixo X\n",
    "        expansion_factor_x = 0 # Expande a escala em 10%\n",
    "\n",
    "        # Calcular os novos limites do eixo X\n",
    "        x_min = self.subgrade_start[0]\n",
    "        x_max = self.subgrade_start[0] + self.subgrade_size[0]\n",
    "        x_range = x_max - x_min\n",
    "        # ax.set_xlim(x_min - expansion_factor_x * x_range, x_max + expansion_factor_x * x_range)\n",
    "\n",
    "        # Manter o eixo Y sem alteração\n",
    "        # ax.set_ylim(y_min, y_max)  # Use os limites que você já definiu para o eixo Y\n",
    "\n",
    "        # Configurar título do gráfico\n",
    "        plt.title(title, fontsize=14)\n",
    "\n",
    "        \n",
    "        # Ajustar o layout\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Mostrar o gráfico\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "        # Gerar posições únicas para os drones\n",
    "        self.posicoes = generate_unique_positions(self.num_uavs, self.subgrade_start, self.subgrade_size, self.resolution)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Inicializar as direções das antenas aleatoriamente\n",
    "        self.direcoes_antena = np.random.uniform(0, 360, size=self.num_uavs)\n",
    "        \n",
    "        # Retornar a observação e informações adicionais\n",
    "        obs = np.array(self.direcoes_antena)\n",
    "        info = {}\n",
    "        return obs, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO COM DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Supondo que seu ambiente seja chamado UAVCommunicationEnv_PPO\n",
    "env = UAVCommunicationEnv_PPO()\n",
    "\n",
    "# Número de episódios para gerar o dataset\n",
    "num_episodes = 1000\n",
    "\n",
    "# Inicializar uma lista para armazenar os dados\n",
    "data = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    # Execute uma etapa para obter a recompensa\n",
    "    action = env.action_space.sample()  # Ou use seu modelo treinado para escolher a ação\n",
    "    obs, reward, done, _, info = env.step(action)\n",
    "    \n",
    "    # Coleta as posições do jammer, posições dos drones, direções das antenas e a recompensa\n",
    "    jammer_pos = env.posicao_jammer\n",
    "    drones_pos = env.posicoes.flatten()  # Flatten para facilitar o armazenamento\n",
    "    direcoes_antena = env.direcoes_antena  # Direções das antenas\n",
    "    recompensa = reward\n",
    "\n",
    "    # Armazenar as informações no formato desejado\n",
    "    data.append({\n",
    "        'Jammer_Pos': jammer_pos,\n",
    "        'Drones_Pos': drones_pos,\n",
    "        'Direcoes_Antena': direcoes_antena,\n",
    "        'Recompensa': recompensa\n",
    "    })\n",
    "\n",
    "# Converter a lista de dados para um DataFrame do pandas\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Expandir as colunas das posições e direções para facilitar a leitura no CSV\n",
    "df['Jammer_X'], df['Jammer_Y'] = zip(*df['Jammer_Pos'])\n",
    "df[['Drone_1_X', 'Drone_1_Y', 'Drone_2_X', 'Drone_2_Y', 'Drone_3_X', 'Drone_3_Y', 'Drone_4_X', 'Drone_4_Y']] = pd.DataFrame(df['Drones_Pos'].tolist(), index=df.index)\n",
    "df[['Direcao_1', 'Direcao_2', 'Direcao_3', 'Direcao_4']] = pd.DataFrame(df['Direcoes_Antena'].tolist(), index=df.index)\n",
    "\n",
    "# Remover as colunas antigas\n",
    "df = df.drop(columns=['Jammer_Pos', 'Drones_Pos', 'Direcoes_Antena'])\n",
    "\n",
    "# Salvar em um arquivo CSV\n",
    "df.to_csv('DATASET-CENARIO2.csv', index=False)\n",
    "\n",
    "print(f'Dataset com {num_episodes} episódios salvo em \"dataset_treino.csv\".')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Callback personalizado para monitorar recompensas\n",
    "class RewardCallback(BaseCallback):\n",
    "    def __init__(self, check_freq: int, verbose: int = 1):\n",
    "        super(RewardCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.rewards = []  # Armazena recompensas para plotagem\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # A cada check_freq passos, calcula a recompensa média e salva\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            # Obter informações do ambiente sobre as recompensas\n",
    "            ep_rewards = [ep_info['Recompensa'] for ep_info in self.locals['infos'] if 'Recompensa' in ep_info]\n",
    "            if len(ep_rewards) > 0:\n",
    "                mean_reward = np.mean(ep_rewards)\n",
    "                self.rewards.append(mean_reward)\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"Step {self.num_timesteps}: Mean Reward = {mean_reward:.2f}\")\n",
    "        return True\n",
    "\n",
    "# Carregar os dados do CSV\n",
    "df = pd.read_csv('DATASET-CENARIO2.csv')\n",
    "\n",
    "# Adicionar as direções das antenas no dataset\n",
    "df['Direcao_1'] = np.random.uniform(0, 360, size=len(df))\n",
    "df['Direcao_2'] = np.random.uniform(0, 360, size=len(df))\n",
    "df['Direcao_3'] = np.random.uniform(0, 360, size=len(df))\n",
    "df['Direcao_4'] = np.random.uniform(0, 360, size=len(df))\n",
    "\n",
    "# Dados de pré-treinamento: separar as colunas de posições, direções e recompensas\n",
    "pre_train_data = df[['Jammer_X', 'Jammer_Y',\n",
    "                     'Drone_1_X', 'Drone_1_Y', \n",
    "                     'Drone_2_X', 'Drone_2_Y', \n",
    "                     'Drone_3_X', 'Drone_3_Y',\n",
    "                     'Drone_4_X', 'Drone_4_Y',\n",
    "                     'Direcao_1', 'Direcao_2', 'Direcao_3', 'Direcao_4',\n",
    "                     'Recompensa']].values\n",
    "\n",
    "# Função para criar o ambiente paralelo\n",
    "def make_env(seed):\n",
    "    def _init():\n",
    "        env = UAVCommunicationEnv_PPO()\n",
    "        env = Monitor(env)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# Definir 1 ambiente paralelo (pode aumentar para n_envs > 1 se desejar)\n",
    "n_envs = 1\n",
    "envs = DummyVecEnv([make_env(i) for i in range(n_envs)])\n",
    "\n",
    "# Função de pré-treinamento (mantida como no código original)\n",
    "def pre_train(model, envs, pre_train_data, pre_train_iters=100):\n",
    "    max_pretrain_steps = 20  # Número máximo de passos por episódio durante o pré-treinamento\n",
    "\n",
    "    for pre_train_iter in range(pre_train_iters):\n",
    "        print(f\"Pre-train iteration {pre_train_iter+1}/{pre_train_iters}\")\n",
    "\n",
    "        for data_index, data in enumerate(pre_train_data):\n",
    "            print(f\"Pre-train data index {data_index+1}/{len(pre_train_data)}\")\n",
    "\n",
    "            # Separar as posições do jammer, posições dos drones, direções das antenas e a recompensa\n",
    "            jammer_position = data[:2]\n",
    "            drone_positions = data[2:10].reshape(-1, 2)\n",
    "            direcoes_antena = data[10:14]\n",
    "            reward = data[-1]\n",
    "\n",
    "            # Definir as posições do jammer, dos drones e as direções das antenas no ambiente\n",
    "            envs.envs[0].unwrapped.posicao_jammer = jammer_position\n",
    "            envs.envs[0].unwrapped.posicoes = drone_positions\n",
    "            envs.envs[0].unwrapped.direcoes_antena = direcoes_antena\n",
    "\n",
    "            # Resetar o ambiente e obter a observação\n",
    "            obs = envs.reset()[0]\n",
    "\n",
    "            done = np.zeros(n_envs, dtype=bool)\n",
    "            step_count = 0  # Contador de passos\n",
    "\n",
    "            while not np.any(done) & step_count < max_pretrain_steps:\n",
    "                env.reset()\n",
    "                # Prever a ação e avaliar\n",
    "                model.policy.set_training_mode(False)\n",
    "                predicted_action, _ = model.predict(obs, deterministic=True)\n",
    "                \n",
    "                # Converter observação e ação em tensores e garantir que estejam no formato correto\n",
    "                obs_tensor = th.tensor(obs, dtype=th.float32).to(model.device).unsqueeze(0)  # Adiciona uma dimensão de lote\n",
    "                predicted_action_tensor = th.tensor(predicted_action, dtype=th.float32).to(model.device).unsqueeze(0)  # Adiciona uma dimensão de lote\n",
    "\n",
    "                # Realizar o passo no ambiente\n",
    "                obs, _, done, _ = envs.step([predicted_action] * n_envs)\n",
    "\n",
    "                # Calcular perdas e atualizar o modelo\n",
    "                model.policy.set_training_mode(True)\n",
    "                model.policy.optimizer.zero_grad()\n",
    "                values, log_prob, entropy = model.policy.evaluate_actions(obs_tensor, predicted_action_tensor)\n",
    "                policy_loss = -log_prob.mean()\n",
    "                value_loss = th.nn.functional.mse_loss(values.flatten(), th.tensor([reward] * n_envs, dtype=th.float32).to(model.device))\n",
    "                loss = policy_loss + value_loss\n",
    "                loss.backward()\n",
    "                model.policy.optimizer.step()\n",
    "\n",
    "                step_count += 1  # Incrementa o contador de passos\n",
    "\n",
    "\n",
    "# Instanciar o modelo PPO com uma taxa de aprendizado mais segura\n",
    "modelPPO = PPO(\"MlpPolicy\", envs, verbose=1,\n",
    "            n_steps=2048,          # Aumenta o número de passos\n",
    "            batch_size=128,        # Aumenta o tamanho do batch\n",
    "            learning_rate=1e-4,    # Taxa de aprendizado mais segura\n",
    "            clip_range=0.2,        # Reduz a faixa de clipping\n",
    "            ent_coef=0.05)         # Aumenta a entropia para incentivar a exploração\n",
    "\n",
    "# Criar callback de recompensa\n",
    "reward_callback = RewardCallback(check_freq=10)\n",
    "\n",
    "# Pré-treinamento do modelo com base nos dados fornecidos\n",
    "print(' -------------------------Pré-Treinar o modelo----------------------------')\n",
    "# pre_train(modelPPO, envs, pre_train_data, pre_train_iters=100)\n",
    "\n",
    "# Treinamento adicional do modelo com callback para registrar recompensas\n",
    "modelPPO.learn(total_timesteps=10000, callback=reward_callback)\n",
    "\n",
    "# Verificar se recompensas foram registradas\n",
    "if len(reward_callback.rewards) == 0:\n",
    "    print(\"Nenhuma recompensa registrada. Verifique o ambiente e o callback.\")\n",
    "\n",
    "# Plotar a evolução da recompensa média ao longo do treinamento\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(len(reward_callback.rewards)) * reward_callback.check_freq, reward_callback.rewards, marker='o', linestyle='-', color='b', label='Recompensa Média')\n",
    "plt.title('Evolução da Recompensa Média durante o Treinamento')\n",
    "plt.xlabel('Checkpoints')\n",
    "plt.ylabel('Recompensa Média')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Salvar o modelo treinado\n",
    "modelPPO.save(\"ppo_uav_communication\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEEP-QLEARNING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "\n",
    "def generate_unique_positions(num_uavs, subgrade_start, subgrade_size, resolution):\n",
    "    x_values = np.arange(subgrade_start[0], subgrade_start[0] + subgrade_size[0], resolution)\n",
    "    y_values = np.arange(subgrade_start[1], subgrade_start[1] + subgrade_size[1], resolution)\n",
    "    possible_positions = np.array(np.meshgrid(x_values, y_values)).T.reshape(-1, 2)\n",
    "    \n",
    "    # Escolher posições aleatórias únicas\n",
    "    indices = np.random.choice(len(possible_positions), size=num_drones, replace=False)\n",
    "    chosen_positions = possible_positions[indices]\n",
    "    \n",
    "    # print(\"Chosen positions:\", chosen_positions)  # Adicionado para depuração\n",
    "    \n",
    "    return chosen_positions\n",
    "\n",
    "class UAVCommunicationEnv_DQL(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, num_uavs=num_drones, area_size=(100, 90)):\n",
    "        super().__init__()\n",
    "        self.num_uavs = num_uavs\n",
    "        self.area_size = area_size\n",
    "        self.posicoes = posicoes.copy()\n",
    "        self.posicao_jammer = posicao_jammer\n",
    "        self.ultimo_info = {}\n",
    "\n",
    "        # Define o espaço de ação: direções das antenas + deslocamentos x e y\n",
    "        self.action_space = spaces.Box(low=np.array([0]*num_uavs + [-40]*num_uavs + [-40]*num_uavs), \n",
    "                                       high=np.array([360]*num_uavs + [40]*num_uavs + [40]*num_uavs), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=0, high=360, shape=(num_uavs,), dtype=np.float32)\n",
    "\n",
    "        self.direcoes_antena = np.random.uniform(0, 360, size=num_uavs)\n",
    "        self.capacidades = []  # Inicializa a lista de capacidades para normalização\n",
    "        self.subgrade_size=subgrade_size\n",
    "        self.subgrade_start=subgrade_start\n",
    "        self.ganhos_df=ganhos_df\n",
    "        self.resolution=resolution\n",
    "\n",
    "    def step(self, action):\n",
    "        direcoes_antena = action[:self.num_uavs]\n",
    "        movimentos_x = action[self.num_uavs:2*self.num_uavs]\n",
    "        movimentos_y = action[2*self.num_uavs:]\n",
    "\n",
    "        self.direcoes_antena = np.random.uniform(0, 360, size=self.num_uavs)\n",
    "        \n",
    "        \n",
    "        # Deslocamento aleatório\n",
    "        deslocamento_x = np.random.uniform(-10, 10, size=self.num_uavs).astype(np.int32)\n",
    "        deslocamento_y = np.random.uniform(-10, 10, size=self.num_uavs).astype(np.int32)\n",
    "\n",
    "        # Atualiza as posições com base nas posições anteriores mais o deslocamento\n",
    "        self.posicoes[:, 0] += deslocamento_x  # Atualiza a posição x dos drones\n",
    "        self.posicoes[:, 1] += deslocamento_y  # Atualiza a posição y dos drones\n",
    "        self.posicoes = generate_unique_positions(self.num_uavs, self.subgrade_start, self.subgrade_size, self.resolution)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # for i in range(self.num_uavs):\n",
    "        #     # Aplicar deslocamento\n",
    "        #     nova_pos_x = self.posicoes[i][0] + movimentos_x[i]\n",
    "        #     nova_pos_y = self.posicoes[i][1] + movimentos_y[i]\n",
    "\n",
    "        #     # Forçar nova posição ao ponto mais próximo da grelha\n",
    "        #     nova_pos_x = np.round(nova_pos_x / resolution) * resolution\n",
    "        #     nova_pos_y = np.round(nova_pos_y / resolution) * resolution\n",
    "\n",
    "        #     # Garantir que a nova posição está dentro da subgrade\n",
    "        #     nova_pos_x = min(max(nova_pos_x, subgrade_start[0]), subgrade_start[0] + subgrade_size[0] - resolution)\n",
    "        #     nova_pos_y = min(max(nova_pos_y, subgrade_start[1]), subgrade_start[1] + subgrade_size[1] - resolution)\n",
    "\n",
    "        #     self.posicoes[i] = np.array([nova_pos_x, nova_pos_y])\n",
    "\n",
    "        \n",
    "        # Verificar e corrigir duplicações de posições\n",
    "        unique_positions, indices = np.unique(self.posicoes, axis=0, return_index=True)\n",
    "        if len(unique_positions) < len(self.posicoes):\n",
    "            for i in range(len(self.posicoes)):\n",
    "                if i not in indices:\n",
    "                    # Se houver duplicatas, gerar uma nova posição válida\n",
    "                    new_pos = generate_unique_positions(1, self.subgrade_start, self.subgrade_size, self.resolution)[0]\n",
    "                    while any(np.array_equal(new_pos, pos) for pos in self.posicoes):\n",
    "                        new_pos = generate_unique_positions(1, self.subgrade_start, self.subgrade_size, self.resolution)[0]\n",
    "                    self.posicoes[i] = new_pos\n",
    "\n",
    "        capacidades_por_link = []\n",
    "\n",
    "        for i in range(self.posicoes.shape[0]):\n",
    "            for j in range(self.posicoes.shape[0]):\n",
    "                if i != j:\n",
    "                    d = distancia(self.posicoes[i], self.posicoes[j])\n",
    "                    ganho_transmissao, ganho_rececao = calcula_ganhos(self.posicoes, self.direcoes_antena, i, j, ganhos_df)\n",
    "                    potencia_recebida = calcula_potencia_recebida(Ptx_dBm, ganho_transmissao, ganho_rececao, d, lambda_m)\n",
    "                    potencia_ruido = calcula_potencia_jammer(self.posicoes[j], self.direcoes_antena[j], self.posicao_jammer, potencia_jammer_dBm, ganhos_df)\n",
    "                    capacidade_canal = calcula_capacidade(potencia_recebida, potencia_ruido)\n",
    "                    capacidades_por_link.append(capacidade_canal)\n",
    "\n",
    "        capacidade_media = np.mean(capacidades_por_link)\n",
    "        capacidade_minima = np.min(capacidades_por_link)\n",
    "\n",
    "        self.capacidades.extend(capacidades_por_link)\n",
    "        if len(self.capacidades) > 1000:\n",
    "            self.capacidades = self.capacidades[-1000:]\n",
    "\n",
    "        min_capacidade = np.min(self.capacidades)\n",
    "        max_capacidade = np.max(self.capacidades)\n",
    "        # capacidade_media_normalizada = (capacidade_media - min_capacidade) / (max_capacidade - min_capacidade + 1e-6)\n",
    "        # capacidade_minima_normalizada = (capacidade_minima - min_capacidade) / (max_capacidade - min_capacidade + 1e-6)\n",
    "\n",
    "        G = nx.Graph()\n",
    "        num_drones = self.posicoes.shape[0]\n",
    "        capacidade_matriz = np.zeros((self.num_uavs, self.num_uavs))\n",
    "        link_index = 0\n",
    "\n",
    "        for i in range(self.num_uavs):\n",
    "            for j in range(self.num_uavs):\n",
    "                if i != j:\n",
    "                    capacidade_matriz[i, j] = capacidades_por_link[link_index]\n",
    "                    link_index += 1\n",
    "\n",
    "        for i in range(num_drones):\n",
    "            for j in range(i + 1, num_drones):\n",
    "                capacidade = capacidade_matriz[i, j]\n",
    "                G.add_edge(i, j, weight=1.0 / capacidade)\n",
    "\n",
    "        bottlenecks = {}\n",
    "        for i in range(num_drones):\n",
    "            for j in range(num_drones):\n",
    "                if i != j:\n",
    "                    try:\n",
    "                        caminho = nx.dijkstra_path(G, source=i, target=j, weight='weight')\n",
    "                        menor_capacidade = float('inf')\n",
    "                        for k in range(len(caminho) - 1):\n",
    "                            cap_atual = capacidade_matriz[caminho[k], caminho[k+1]]\n",
    "                            if cap_atual < menor_capacidade:\n",
    "                                menor_capacidade = cap_atual\n",
    "                        bottlenecks[(i, j)] = (caminho, menor_capacidade)\n",
    "                    except nx.NetworkXNoPath:\n",
    "                        print(f\"Não há caminho do nó {i} para o nó {j}\")\n",
    "\n",
    "        capacidade_bottleneck_media = np.mean([bottleneck for caminho, bottleneck in bottlenecks.values()])\n",
    "        capacidade_bottleneck_minima = np.min([bottleneck for caminho, bottleneck in bottlenecks.values()])\n",
    "\n",
    "        # capacidade_bottleneck_media_normalizada = (capacidade_bottleneck_media - min_capacidade) / (max_capacidade - min_capacidade + 1e-6)\n",
    "        # capacidade_bottleneck_minima_normalizada = (capacidade_bottleneck_minima - min_capacidade) / (max_capacidade - min_capacidade + 1e-6)\n",
    "\n",
    "        distancia_jammer = np.mean([distancia(pos, self.posicao_jammer) for pos in self.posicoes])\n",
    "        penalidade_distancia_jammer = -(distancia_jammer ** 2)  # Ajustado para escala apropriada\n",
    "\n",
    "        distancias_entre_drones = [distancia(self.posicoes[i], self.posicoes[j]) for i in range(num_drones) for j in range(i+1, num_drones)]\n",
    "        distancia_minima_entre_drones = np.min(distancias_entre_drones)\n",
    "        penalidade_proximidade_drones = (max(0, (30 - distancia_minima_entre_drones) ** 2))  # Ajustado para escala apropriada\n",
    "\n",
    "        # Ajuste da função de recompensa para refletir as penalidades não normalizadas\n",
    "        recompensa = capacidade_media * capacidade_bottleneck_minima - ( 0 * penalidade_distancia_jammer + 0 * penalidade_proximidade_drones)\n",
    "\n",
    "        capacidades_por_link = [round(capacidade, 3) for capacidade in capacidades_por_link]\n",
    "        capacidade_media = round(capacidade_media, 3)\n",
    "\n",
    "        info = {\n",
    "            'Recompensa': recompensa,\n",
    "            'Capacidade média [Kbps]': capacidade_media,\n",
    "            'Capacidades_por_link [Kbps]': capacidades_por_link,\n",
    "            'Matriz de Capacidades [Kbps]': capacidade_matriz,\n",
    "            'Capacidade mínima [Kbps]': capacidade_minima,\n",
    "            # 'Capacidade média normalizada': capacidade_media_normalizada,\n",
    "            # 'Capacidade mínima normalizada': capacidade_minima_normalizada,\n",
    "            'Capacidade bottleneck média': capacidade_bottleneck_media,\n",
    "            'Capacidade bottleneck mínima': capacidade_bottleneck_minima,\n",
    "            # 'Capacidade bottleneck média normalizada': capacidade_bottleneck_media_normalizada,\n",
    "            # 'Capacidade bottleneck mínima normalizada': capacidade_bottleneck_minima_normalizada,\n",
    "            'Penalidade distância ao jammer': penalidade_distancia_jammer,\n",
    "            'Penalidade proximidade entre drones': penalidade_proximidade_drones\n",
    "        }\n",
    "\n",
    "        done = False\n",
    "        return np.array(self.direcoes_antena), recompensa, done, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        sns.set(style=\"whitegrid\")\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        subgrade_start = self.subgrade_start\n",
    "        subgrade_size = self.subgrade_size\n",
    "        resolution = 5\n",
    "\n",
    "        rect = plt.Rectangle(subgrade_start, subgrade_size[0], subgrade_size[1], linewidth=1, edgecolor='blue', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Desenhar linhas verticais da subgrade dentro do limite da área\n",
    "        for x in np.arange(subgrade_start[0], subgrade_start[0] + subgrade_size[0] + resolution, resolution):\n",
    "            ax.axvline(x, color='blue', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        # Desenhar linhas horizontais da subgrade dentro do limite da área\n",
    "        for y in np.arange(subgrade_start[1], subgrade_start[1] + subgrade_size[1] + resolution, resolution):\n",
    "            ax.axhline(y, color='blue', linestyle='--', linewidth=0.5)\n",
    "\n",
    "        # Desenhar os drones\n",
    "        for i, pos in enumerate(self.posicoes):\n",
    "            ax.scatter(pos[0], pos[1], color='blue', s=100, label='Drone' if i == 0 else \"\")\n",
    "            ax.text(pos[0], pos[1] - 2, f'{i}', horizontalalignment='center', color='white', fontweight='bold')\n",
    "\n",
    "\n",
    "        angulos = np.deg2rad(self.ganhos_df['angulo'])\n",
    "        ganhos = self.ganhos_df['ganho']\n",
    "\n",
    "        # Normalizar os ganhos para o intervalo [0, 1]\n",
    "        ganhos_normalizados = (ganhos - ganhos.min()) / (ganhos.max() - ganhos.min())\n",
    "\n",
    "        # Desenhar o diagrama de radiação sem adicionar ao gráfico principal\n",
    "        direcao = self.direcoes_antena[0]\n",
    "        angulos_rotacionados = angulos + np.deg2rad(direcao)\n",
    "        escala = 6  # Ajuste este valor conforme necessário\n",
    "        contorno_x = ganhos_normalizados * np.cos(angulos_rotacionados) * escala\n",
    "        contorno_y = ganhos_normalizados * np.sin(angulos_rotacionados) * escala\n",
    "\n",
    "        for i, (x, y) in enumerate(self.posicoes):\n",
    "            direcao = self.direcoes_antena[i]\n",
    "            angulos_rotacionados = angulos + np.deg2rad(direcao)\n",
    "            contorno_x = x + ganhos_normalizados * np.cos(angulos_rotacionados) * escala\n",
    "            contorno_y = y + ganhos_normalizados * np.sin(angulos_rotacionados) * escala\n",
    "            ax.plot(contorno_x, contorno_y, color='blue', alpha=0.7)\n",
    "\n",
    "        ax.scatter(self.posicao_jammer[0], self.posicao_jammer[1], color='red', s=100, marker='o', label='Jammer')\n",
    "\n",
    "        class CustomHandlerPatch(HandlerPatch):\n",
    "            def create_artists(self, legend, orig_handle, xdescent, ydescent, width, height, fontsize, trans):\n",
    "                offset_x = width * 0.3  # Ajuste este valor para mover o patch para a direita\n",
    "                offset_y = ydescent - height * 0.5\n",
    "                patch = patches.Polygon(\n",
    "                    np.column_stack((ganhos_normalizados * np.cos(angulos) * escala * 2.5 + offset_x, ganhos_normalizados * np.sin(angulos) * escala * 1.8)), \n",
    "                    closed=True, color='blue', alpha=0.9, transform=trans\n",
    "                )\n",
    "                return [patch]\n",
    "\n",
    "        custom_patch = patches.Patch(color='blue', label='Diagrama de Radiação')\n",
    "\n",
    "        # Adicionar a legenda\n",
    "        handles = [\n",
    "            mlines.Line2D([], [], color='blue', marker='o', linestyle='None', markersize=10, label='Drone'),\n",
    "            mlines.Line2D([], [], color='red', marker='o', linestyle='None', markersize=10, label='Jammer'),\n",
    "            custom_patch\n",
    "        ]\n",
    "        \n",
    "        for i, pos in enumerate(self.posicoes):\n",
    "            handles.append(\n",
    "                mlines.Line2D([], [], color='blue', marker='', linestyle='None', markersize=10,\n",
    "                            label=f'Drone {i}: Pos ({pos[0]}, {pos[1]}), Dir {self.direcoes_antena[i]:.1f}°')\n",
    "            )\n",
    "        \n",
    "        handles.append(\n",
    "            mlines.Line2D([], [], color='none', marker='', linestyle='None', markersize=0,\n",
    "                        label=f'Capacidade Média [bps]: {cap_media:.2f}')\n",
    "        )\n",
    "        handles.append(\n",
    "            mlines.Line2D([], [], color='none', marker='', linestyle='None', markersize=0,\n",
    "                        label=f'Bottleneck Mínimo [bps]: {bottleneck:.2f}')\n",
    "        )\n",
    "        \n",
    "        # Ajuste do tamanho da legenda com fontsize e disposição horizontal\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), fontsize='small', ncol=3, handles=handles, handler_map={custom_patch: CustomHandlerPatch()})\n",
    "        # ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize='small',borderpad=1, handles=handles, handler_map={custom_patch: CustomHandlerPatch(), (None, None): HandlerTuple()})\n",
    "        \n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_xlim(0, self.area_size[0])\n",
    "        ax.set_ylim(0, self.area_size[1])\n",
    "        ax.set_yticks(np.arange(0, self.area_size[1] + 1, 20))\n",
    "    \n",
    "        plt.title(title)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "        # Gerar posições únicas para os drones\n",
    "        self.posicoes=posicoes\n",
    "        # self.posicoes = generate_unique_positions(self.num_uavs, self.subgrade_start, self.subgrade_size, self.resolution)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Inicializar as direções das antenas aleatoriamente\n",
    "        self.direcoes_antena = direcoes_antena\n",
    "        \n",
    "        # Retornar a observação e informações adicionais\n",
    "        obs = np.array(self.direcoes_antena)\n",
    "        info = {}\n",
    "        return obs, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOFT ACTOR CRITIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Rede neural para os críticos (Q-networks)\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        return self.fc5(x)\n",
    "\n",
    "# Rede neural para o ator (policy network)\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.mu_layer = nn.Linear(512, output_dim)\n",
    "        self.log_std_layer = nn.Linear(512, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        mu = self.mu_layer(x)\n",
    "        log_std = self.log_std_layer(x)\n",
    "        log_std = torch.clamp(log_std, -20, 2)  # Para estabilidade numérica\n",
    "        return mu, log_std\n",
    "\n",
    "    def sample(self, state):\n",
    "        mu, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        normal = torch.distributions.Normal(mu, std)\n",
    "        z = normal.rsample()  # Reparametrização\n",
    "        action = torch.tanh(z)\n",
    "        log_prob = normal.log_prob(z) - torch.log(1 - action.pow(2) + 1e-6)\n",
    "        return action, log_prob.sum(dim=-1)\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=100000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "\n",
    "class SACAgent:\n",
    "    def __init__(self, state_dim, action_dim, action_range):\n",
    "        self.actor = Actor(state_dim, action_dim)\n",
    "        self.critic1 = Critic(state_dim + action_dim, 1)\n",
    "        self.critic2 = Critic(state_dim + action_dim, 1)\n",
    "        self.target_critic1 = Critic(state_dim + action_dim, 1)\n",
    "        self.target_critic2 = Critic(state_dim + action_dim, 1)\n",
    "        \n",
    "        # Verifique as dimensões dos estados e ações\n",
    "        print(f\"State dim: {state_dim}, Action dim: {action_dim}\")\n",
    "        \n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=1e-4)\n",
    "        self.critic1_optimizer = optim.Adam(self.critic1.parameters(), lr=1e-4)\n",
    "        self.critic2_optimizer = optim.Adam(self.critic2.parameters(), lr=1e-4)\n",
    "\n",
    "        self.target_critic1.load_state_dict(self.critic1.state_dict())\n",
    "        self.target_critic2.load_state_dict(self.critic2.state_dict())\n",
    "\n",
    "        self.replay_buffer = ReplayBuffer()\n",
    "        self.gamma = 0.99\n",
    "        self.tau = 0.01\n",
    "        self.alpha = 0.001  # Entropy coefficient\n",
    "        self.action_range = action_range\n",
    "        \n",
    "        self.reward_history = []\n",
    "        self.min_reward = float('inf')\n",
    "        self.max_reward = -float('inf')\n",
    "\n",
    "    def update_reward_statistics(self, reward):\n",
    "        self.reward_history.append(reward)\n",
    "        if reward < self.min_reward:\n",
    "            self.min_reward = reward\n",
    "        if reward > self.max_reward:\n",
    "            self.max_reward = reward\n",
    "\n",
    "    def normalize_reward(self, reward):\n",
    "        self.update_reward_statistics(reward)\n",
    "        if self.max_reward == self.min_reward:\n",
    "            return 0.0  # Evita divisão por zero\n",
    "        return (reward - self.min_reward) / (self.max_reward - self.min_reward)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        # Salvar os modelos dos atores e críticos\n",
    "        torch.save({\n",
    "            'actor_state_dict': self.actor.state_dict(),\n",
    "            'critic1_state_dict': self.critic1.state_dict(),\n",
    "            'critic2_state_dict': self.critic2.state_dict(),\n",
    "            'actor_optimizer_state_dict': self.actor_optimizer.state_dict(),\n",
    "            'critic1_optimizer_state_dict': self.critic1_optimizer.state_dict(),\n",
    "            'critic2_optimizer_state_dict': self.critic2_optimizer.state_dict(),\n",
    "        }, filepath)\n",
    "        print(f\"Model saved to {filepath}\")\n",
    "\n",
    "    def load(self, filepath):\n",
    "        # Carregar os modelos dos atores e críticos\n",
    "        checkpoint = torch.load(filepath)\n",
    "        self.actor.load_state_dict(checkpoint['actor_state_dict'])\n",
    "        self.critic1.load_state_dict(checkpoint['critic1_state_dict'])\n",
    "        self.critic2.load_state_dict(checkpoint['critic2_state_dict'])\n",
    "        self.actor_optimizer.load_state_dict(checkpoint['actor_optimizer_state_dict'])\n",
    "        self.critic1_optimizer.load_state_dict(checkpoint['critic1_optimizer_state_dict'])\n",
    "        self.critic2_optimizer.load_state_dict(checkpoint['critic2_optimizer_state_dict'])\n",
    "        print(f\"Model loaded from {filepath}\")\n",
    "    \n",
    "    \n",
    "    def select_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)  # Certifique-se de que o estado é um vetor e converta para tensor\n",
    "        action, _ = self.actor.sample(state)\n",
    "        return action.detach().numpy().flatten()\n",
    "\n",
    "    def update(self, batch_size):\n",
    "        if self.replay_buffer.size() < batch_size:\n",
    "            return\n",
    "\n",
    "        samples = self.replay_buffer.sample(batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*samples)\n",
    "        states = torch.FloatTensor(np.array(states))\n",
    "        actions = torch.FloatTensor(np.array(actions))\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
    "        next_states = torch.FloatTensor(np.array(next_states))\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_actions, next_log_probs = self.actor.sample(next_states)\n",
    "            target_q1 = self.target_critic1(torch.cat([next_states, next_actions], 1))\n",
    "            target_q2 = self.target_critic2(torch.cat([next_states, next_actions], 1))\n",
    "            target_q = rewards + (1 - dones) * self.gamma * (torch.min(target_q1, target_q2) - self.alpha * next_log_probs.unsqueeze(1))\n",
    "\n",
    "        q1 = self.critic1(torch.cat([states, actions], 1))\n",
    "        q2 = self.critic2(torch.cat([states, actions], 1))\n",
    "        critic1_loss = nn.MSELoss()(q1, target_q)\n",
    "        critic2_loss = nn.MSELoss()(q2, target_q)\n",
    "\n",
    "        self.critic1_optimizer.zero_grad()\n",
    "        critic1_loss.backward()\n",
    "        self.critic1_optimizer.step()\n",
    "\n",
    "        self.critic2_optimizer.zero_grad()\n",
    "        critic2_loss.backward()\n",
    "        self.critic2_optimizer.step()\n",
    "\n",
    "        actions, log_probs = self.actor.sample(states)\n",
    "        q1_pi = self.critic1(torch.cat([states, actions], 1))\n",
    "        q2_pi = self.critic2(torch.cat([states, actions], 1))\n",
    "        actor_loss = (self.alpha * log_probs - torch.min(q1_pi, q2_pi)).mean()\n",
    "\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # Update target networks\n",
    "        for target_param, param in zip(self.target_critic1.parameters(), self.critic1.parameters()):\n",
    "            target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "        for target_param, param in zip(self.target_critic2.parameters(), self.critic2.parameters()):\n",
    "            target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "\n",
    "# Defina o ambiente e os parâmetros de treinamento\n",
    "env = UAVCommunicationEnv_DQL()  # Substitua pelo seu ambiente\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "action_range = [env.action_space.low, env.action_space.high]\n",
    "num_episodes = 2000\n",
    "batch_size = 256\n",
    "\n",
    "# Inicialize o agente\n",
    "agent = SACAgent(state_dim, action_dim, action_range)\n",
    "\n",
    "# Variáveis para monitorar o desempenho\n",
    "reward_history = []\n",
    "average_rewards = []\n",
    "\n",
    "# Loop de treinamento\n",
    "for episode in range(num_episodes):\n",
    "    state,_ = env.reset()\n",
    "    print(f\"Estado inicial após reset: {state}, Dimensão: {len(state)}\")  # Debugging\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Seleciona ação e executa no ambiente\n",
    "        action = agent.select_action(state)\n",
    "        if len(state) != state_dim:\n",
    "            raise ValueError(f\"Dimensão do estado ({len(state)}) não corresponde a state_dim ({state_dim}). Verifique o ambiente.\")\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # Armazena experiência no buffer\n",
    "        agent.replay_buffer.add((state, action, reward, next_state, done))\n",
    "\n",
    "        # Atualiza o modelo a cada interação, se o buffer tiver o tamanho suficiente\n",
    "        if agent.replay_buffer.size() > batch_size:\n",
    "            agent.update(batch_size)\n",
    "\n",
    "        # Atualiza o estado e o episódio de recompensa acumulada\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "        done =True\n",
    "        \n",
    "        \n",
    "\n",
    "    # Armazena recompensas e calcula a média a cada 50 episódios\n",
    "    reward_history.append(episode_reward)\n",
    "    if (episode + 1) % 50 == 0:\n",
    "        avg_reward = np.mean(reward_history[-50:])\n",
    "        average_rewards.append(avg_reward)\n",
    "        print(f\"Episódio {episode + 1}: Recompensa média dos últimos 50 episódios: {avg_reward}\")\n",
    "\n",
    "# Salve o modelo treinado\n",
    "agent.save(\"sac_uav_model.pth\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(50, num_episodes + 1, 50), average_rewards_normalized, linestyle='-', color='b', label='Average Reward')\n",
    "# plt.plot(mean_timesteps_array, mean_rewards, linestyle='-', color='b', label='Average Reward')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('')\n",
    "plt.title('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SACAgent(state_dim, action_dim, action_range)\n",
    "agent.load(\"C:/Users/tass/OneDrive - EXÉRCITO PORTUGUÊS/Ambiente de Trabalho/Tese/Simulaçãoes/best_models/sac_best_model.pth\")\n",
    "env=UAVCommunicationEnv_DQL()\n",
    "env.reset()\n",
    "# Inicializar variáveis para armazenar a melhor recompensa e o melhor episódio\n",
    "best_reward = -float('inf')\n",
    "best_episode = None\n",
    "best_episode_steps = []\n",
    "\n",
    "# Executar o modelo no ambiente 100 vezes\n",
    "num_test_episodes = 1000\n",
    "\n",
    "for episode in range(num_test_episodes):\n",
    "    state, _ = env.reset()\n",
    "    episode_reward = 0\n",
    "    episode_steps = []\n",
    "\n",
    "    \n",
    "    action = agent.select_action(state)  # Seleciona ação sem exploração adicional\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    episode_steps.append((state, action))  # Armazena o estado e a ação\n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "\n",
    "    # print(f\"Test Episode: {episode}, Reward: {episode_reward}\")\n",
    "\n",
    "    # Se este episódio for o melhor até agora, salvá-lo\n",
    "    if episode_reward > best_reward:\n",
    "        best_reward = episode_reward\n",
    "        best_episode = episode\n",
    "        best_episode_steps = episode_steps\n",
    "\n",
    "# Renderizar o melhor episódio\n",
    "print(f\"Best Episode: {best_episode}, Best Reward: {best_reward}\")\n",
    "\n",
    "# Resetar o ambiente\n",
    "state, _ = env.reset()\n",
    "# env.render()\n",
    "\n",
    "for step in best_episode_steps:\n",
    "    state, action = step\n",
    "    env.step(action)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    title = 'Direções e Posições Estabelecidas - Algoritmo SAC'\n",
    "    bottleneck = info['Capacidade bottleneck mínima']\n",
    "    cap_media = info['Capacidade média [Kbps]']\n",
    "    print(info['Capacidades_por_link [Kbps]'])\n",
    "    env.render()\n",
    "\n",
    "print(\"Renderização do melhor episódio concluída.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
